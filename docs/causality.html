<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Analiza współzależności pomiędzy zmiennymi | Podstawy statystyki</title>
  <meta name="description" content="(c) Tomasz Przechlewski / CC-BY license" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Analiza współzależności pomiędzy zmiennymi | Podstawy statystyki" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="(c) Tomasz Przechlewski / CC-BY license" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Analiza współzależności pomiędzy zmiennymi | Podstawy statystyki" />
  
  <meta name="twitter:description" content="(c) Tomasz Przechlewski / CC-BY license" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interference.html"/>
<link rel="next" href="surveyexamples.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://hrpunio.github.io/SMI_Bookdown/przedmiotbadan.html">Podstawy statystyki</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="wstęp.html"><a href="wstęp.html"><i class="fa fa-check"></i>Wstęp</a></li>
<li class="chapter" data-level="1" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html"><i class="fa fa-check"></i><b>1</b> Przedmiot i metody badań statystycznych</a>
<ul>
<li class="chapter" data-level="1.1" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#przedmiotS"><i class="fa fa-check"></i><b>1.1</b> Przedmiot statystyki</a></li>
<li class="chapter" data-level="1.2" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#podstawowe-pojęcia"><i class="fa fa-check"></i><b>1.2</b> Podstawowe pojęcia</a></li>
<li class="chapter" data-level="1.3" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#pomiar"><i class="fa fa-check"></i><b>1.3</b> Pomiar</a></li>
<li class="chapter" data-level="1.4" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#rodzaje-i-sposoby-analizy-danych"><i class="fa fa-check"></i><b>1.4</b> Rodzaje i sposoby analizy danych</a></li>
<li class="chapter" data-level="1.5" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#sposoby-pomiaru-danych-i-organizacja-badania"><i class="fa fa-check"></i><b>1.5</b> Sposoby pomiaru danych i organizacja badania</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#przykłady-badań"><i class="fa fa-check"></i><b>1.5.1</b> Przykłady badań</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#miary-częstości-chorób"><i class="fa fa-check"></i><b>1.6</b> Miary częstości chorób</a></li>
<li class="chapter" data-level="1.7" data-path="przedmiotbadan.html"><a href="przedmiotbadan.html#oprogramowanie"><i class="fa fa-check"></i><b>1.7</b> Oprogramowanie</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analiza1z.html"><a href="analiza1z.html"><i class="fa fa-check"></i><b>2</b> Analiza jednej zmiennej</a>
<ul>
<li class="chapter" data-level="2.1" data-path="analiza1z.html"><a href="analiza1z.html#tablice-statystyczne"><i class="fa fa-check"></i><b>2.1</b> Tablice statystyczne</a></li>
<li class="chapter" data-level="2.2" data-path="analiza1z.html"><a href="analiza1z.html#wykresy"><i class="fa fa-check"></i><b>2.2</b> Wykresy</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="analiza1z.html"><a href="analiza1z.html#skala-nominalna-i-porządkowa"><i class="fa fa-check"></i><b>2.2.1</b> Skala nominalna i porządkowa</a></li>
<li class="chapter" data-level="2.2.2" data-path="analiza1z.html"><a href="analiza1z.html#skala-liczbowa"><i class="fa fa-check"></i><b>2.2.2</b> Skala liczbowa</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="analiza1z.html"><a href="analiza1z.html#fnightingale"><i class="fa fa-check"></i><b>2.3</b> Statystyczka Florence Nightingale</a></li>
<li class="chapter" data-level="2.4" data-path="analiza1z.html"><a href="analiza1z.html#analiza-parametryczna"><i class="fa fa-check"></i><b>2.4</b> Analiza parametryczna</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="analiza1z.html"><a href="analiza1z.html#miary-położenia"><i class="fa fa-check"></i><b>2.4.1</b> Miary położenia</a></li>
<li class="chapter" data-level="2.4.2" data-path="analiza1z.html"><a href="analiza1z.html#miary-zmienności"><i class="fa fa-check"></i><b>2.4.2</b> Miary zmienności</a></li>
<li class="chapter" data-level="2.4.3" data-path="analiza1z.html"><a href="analiza1z.html#miary-asymetrii"><i class="fa fa-check"></i><b>2.4.3</b> Miary asymetrii</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analiza1z.html"><a href="analiza1z.html#porównanie-wielu-rozkładów"><i class="fa fa-check"></i><b>2.5</b> Porównanie wielu rozkładów</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="analiza1z.html"><a href="analiza1z.html#wykres-pudełkowy"><i class="fa fa-check"></i><b>2.5.1</b> Wykres pudełkowy</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="analiza1z.html"><a href="analiza1z.html#zestawienie-metod-opisu-statystycznego"><i class="fa fa-check"></i><b>2.6</b> Zestawienie metod opisu statystycznego</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interference.html"><a href="interference.html"><i class="fa fa-check"></i><b>3</b> Wprowadzenie do wnioskowania statystycznego</a>
<ul>
<li class="chapter" data-level="3.1" data-path="interference.html"><a href="interference.html#masa-ciała-uczestników-pś-w-rugby"><i class="fa fa-check"></i><b>3.1</b> Masa ciała uczestników PŚ w rugby</a></li>
<li class="chapter" data-level="3.2" data-path="interference.html"><a href="interference.html#wiek-kandydatów-na-radnych"><i class="fa fa-check"></i><b>3.2</b> Wiek kandydatów na radnych</a></li>
<li class="chapter" data-level="3.3" data-path="interference.html"><a href="interference.html#rozkład-normalny"><i class="fa fa-check"></i><b>3.3</b> Rozkład normalny</a></li>
<li class="chapter" data-level="3.4" data-path="interference.html"><a href="interference.html#odsetek-kobiet-wśród-kandydatów-na-radnych"><i class="fa fa-check"></i><b>3.4</b> Odsetek kobiet wśród kandydatów na radnych</a></li>
<li class="chapter" data-level="3.5" data-path="interference.html"><a href="interference.html#wnioskowanie-statystyczne"><i class="fa fa-check"></i><b>3.5</b> Wnioskowanie statystyczne</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="interference.html"><a href="interference.html#estymacja-punktowa"><i class="fa fa-check"></i><b>3.5.1</b> Estymacja punktowa</a></li>
<li class="chapter" data-level="3.5.2" data-path="interference.html"><a href="interference.html#estymacja-przedziałowa"><i class="fa fa-check"></i><b>3.5.2</b> Estymacja przedziałowa</a></li>
<li class="chapter" data-level="3.5.3" data-path="interference.html"><a href="interference.html#testowanie-hipotez"><i class="fa fa-check"></i><b>3.5.3</b> Testowanie hipotez</a></li>
<li class="chapter" data-level="3.5.4" data-path="interference.html"><a href="interference.html#testy-nieparametryczne"><i class="fa fa-check"></i><b>3.5.4</b> Testy nieparametryczne</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="interference.html"><a href="interference.html#statystyk-carl-pearson"><i class="fa fa-check"></i><b>3.6</b> Statystyk Carl Pearson</a></li>
<li class="chapter" data-level="3.7" data-path="interference.html"><a href="interference.html#słownik-terminów-które-warto-znać"><i class="fa fa-check"></i><b>3.7</b> Słownik terminów, które warto znać</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>4</b> Analiza współzależności pomiędzy zmiennymi</a>
<ul>
<li class="chapter" data-level="4.1" data-path="causality.html"><a href="causality.html#dwie-zmienne-nominalne"><i class="fa fa-check"></i><b>4.1</b> Dwie zmienne nominalne</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="causality.html"><a href="causality.html#oddsSec"><i class="fa fa-check"></i><b>4.1.1</b> Ryzyko względne oraz iloraz szans</a></li>
<li class="chapter" data-level="4.1.2" data-path="causality.html"><a href="causality.html#przedziały-ufności-dla-ryzyka-względnego-i-ilorazu-szans"><i class="fa fa-check"></i><b>4.1.2</b> Przedziały ufności dla ryzyka względnego i ilorazu szans</a></li>
<li class="chapter" data-level="4.1.3" data-path="causality.html"><a href="causality.html#tabele-wielodzielne"><i class="fa fa-check"></i><b>4.1.3</b> Tabele wielodzielne</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="causality.html"><a href="causality.html#zmienna-liczbowa-i-zmienna-nominalna"><i class="fa fa-check"></i><b>4.2</b> Zmienna liczbowa i zmienna nominalna</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="causality.html"><a href="causality.html#test-t-welcha"><i class="fa fa-check"></i><b>4.2.1</b> Test <span class="math inline">\(t\)</span> Welcha</a></li>
<li class="chapter" data-level="4.2.2" data-path="causality.html"><a href="causality.html#testowanie-normalności"><i class="fa fa-check"></i><b>4.2.2</b> Testowanie normalności</a></li>
<li class="chapter" data-level="4.2.3" data-path="causality.html"><a href="causality.html#test-u-manna-whitneya"><i class="fa fa-check"></i><b>4.2.3</b> Test U Manna-Whitneya</a></li>
<li class="chapter" data-level="4.2.4" data-path="causality.html"><a href="causality.html#test-anova"><i class="fa fa-check"></i><b>4.2.4</b> Test ANOVA</a></li>
<li class="chapter" data-level="4.2.5" data-path="causality.html"><a href="causality.html#test-kruskala-wallisa"><i class="fa fa-check"></i><b>4.2.5</b> Test Kruskala-Wallisa</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="causality.html"><a href="causality.html#dwie-zmienne-liczbowe"><i class="fa fa-check"></i><b>4.3</b> Dwie zmienne liczbowe</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="causality.html"><a href="causality.html#korelacyjny-wykres-rozrzutu"><i class="fa fa-check"></i><b>4.3.1</b> Korelacyjny wykres rozrzutu</a></li>
<li class="chapter" data-level="4.3.2" data-path="causality.html"><a href="causality.html#PearsonCoeff"><i class="fa fa-check"></i><b>4.3.2</b> Pomiar siły zależności: współczynnik korelacji liniowej Pearsona</a></li>
<li class="chapter" data-level="4.3.3" data-path="causality.html"><a href="causality.html#macierz-korelacji"><i class="fa fa-check"></i><b>4.3.3</b> Macierz korelacji</a></li>
<li class="chapter" data-level="4.3.4" data-path="causality.html"><a href="causality.html#pomiar-siły-zależności-regresja-liniowa"><i class="fa fa-check"></i><b>4.3.4</b> Pomiar siły zależności: regresja liniowa</a></li>
<li class="chapter" data-level="4.3.5" data-path="causality.html"><a href="causality.html#regProsta"><i class="fa fa-check"></i><b>4.3.5</b> Regresja prosta</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="causality.html"><a href="causality.html#zmienna-liczbowa-i-zmienne-liczbowe-lub-nominalne"><i class="fa fa-check"></i><b>4.4</b> Zmienna liczbowa i zmienne liczbowe lub nominalne</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="causality.html"><a href="causality.html#regresja-wieloraka"><i class="fa fa-check"></i><b>4.4.1</b> Regresja wieloraka</a></li>
<li class="chapter" data-level="4.4.2" data-path="causality.html"><a href="causality.html#zmienne-zero-jedynkowe"><i class="fa fa-check"></i><b>4.4.2</b> Zmienne zero-jedynkowe</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="causality.html"><a href="causality.html#przypadek-specjalny-regresja-logistyczna"><i class="fa fa-check"></i><b>4.5</b> Przypadek specjalny: regresja logistyczna</a></li>
<li class="chapter" data-level="4.6" data-path="causality.html"><a href="causality.html#przypadek-specjalny-co-najmniej-dwie-zmienne-porządkowe"><i class="fa fa-check"></i><b>4.6</b> Przypadek specjalny: co najmniej dwie zmienne porządkowe</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="causality.html"><a href="causality.html#pomiar-siły-zależności-współczynnik-korelacji-rang"><i class="fa fa-check"></i><b>4.6.1</b> Pomiar siły zależności: współczynnik korelacji rang</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="causality.html"><a href="causality.html#podsumowanie"><i class="fa fa-check"></i><b>4.7</b> Podsumowanie</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="surveyexamples.html"><a href="surveyexamples.html"><i class="fa fa-check"></i><b>5</b> Przykłady badań ankietowych</a>
<ul>
<li class="chapter" data-level="5.1" data-path="surveyexamples.html"><a href="surveyexamples.html#jak-zacząć-badanie"><i class="fa fa-check"></i><b>5.1</b> Jak zacząć badanie?</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="surveyexamples.html"><a href="surveyexamples.html#mierzenie-twardych-faktów-vs-mierzenie-przekonań"><i class="fa fa-check"></i><b>5.1.1</b> Mierzenie twardych faktów vs mierzenie przekonań</a></li>
<li class="chapter" data-level="5.1.2" data-path="surveyexamples.html"><a href="surveyexamples.html#pomiar-przekonań-wartości-i-postaw"><i class="fa fa-check"></i><b>5.1.2</b> Pomiar przekonań, wartości i postaw</a></li>
<li class="chapter" data-level="5.1.3" data-path="surveyexamples.html"><a href="surveyexamples.html#skala-likerta"><i class="fa fa-check"></i><b>5.1.3</b> Skala Likerta</a></li>
<li class="chapter" data-level="5.1.4" data-path="surveyexamples.html"><a href="surveyexamples.html#skala-pomiarowa-czyli-inwentarz-albo-kwestionariusz"><i class="fa fa-check"></i><b>5.1.4</b> Skala pomiarowa, czyli inwentarz albo kwestionariusz</a></li>
<li class="chapter" data-level="5.1.5" data-path="surveyexamples.html"><a href="surveyexamples.html#model-pomiaru"><i class="fa fa-check"></i><b>5.1.5</b> Model pomiaru</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="surveyexamples.html"><a href="surveyexamples.html#wiedza-na-temat-szkodliwości-palenia-i-jej-uwarunkowania-wśród-studentów-psw"><i class="fa fa-check"></i><b>5.2</b> Wiedza na temat szkodliwości palenia i jej uwarunkowania wśród studentów PSW</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="surveyexamples.html"><a href="surveyexamples.html#cel"><i class="fa fa-check"></i><b>5.2.1</b> Cel</a></li>
<li class="chapter" data-level="5.2.2" data-path="surveyexamples.html"><a href="surveyexamples.html#metoda"><i class="fa fa-check"></i><b>5.2.2</b> Metoda</a></li>
<li class="chapter" data-level="5.2.3" data-path="surveyexamples.html"><a href="surveyexamples.html#metryczka-analiza-respondentów"><i class="fa fa-check"></i><b>5.2.3</b> Metryczka (analiza respondentów)</a></li>
<li class="chapter" data-level="5.2.4" data-path="surveyexamples.html"><a href="surveyexamples.html#weryfikacja-hipotezy-1"><i class="fa fa-check"></i><b>5.2.4</b> Weryfikacja hipotezy 1</a></li>
<li class="chapter" data-level="5.2.5" data-path="surveyexamples.html"><a href="surveyexamples.html#weryfikacja-hipotezy-2"><i class="fa fa-check"></i><b>5.2.5</b> Weryfikacja hipotezy 2</a></li>
<li class="chapter" data-level="5.2.6" data-path="surveyexamples.html"><a href="surveyexamples.html#weryfikacja-hipotez-35"><i class="fa fa-check"></i><b>5.2.6</b> Weryfikacja hipotez 3–5</a></li>
<li class="chapter" data-level="5.2.7" data-path="surveyexamples.html"><a href="surveyexamples.html#wnioski"><i class="fa fa-check"></i><b>5.2.7</b> Wnioski</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="surveyexamples.html"><a href="surveyexamples.html#depresja-i-jej-uwarunkowania-wśród-studentów-powiślańskiej-szkoły-wyższej"><i class="fa fa-check"></i><b>5.3</b> Depresja i jej uwarunkowania wśród studentów Powiślańskiej Szkoły Wyższej</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="surveyexamples.html"><a href="surveyexamples.html#cel-1"><i class="fa fa-check"></i><b>5.3.1</b> Cel</a></li>
<li class="chapter" data-level="5.3.2" data-path="surveyexamples.html"><a href="surveyexamples.html#metoda-1"><i class="fa fa-check"></i><b>5.3.2</b> Metoda</a></li>
<li class="chapter" data-level="5.3.3" data-path="surveyexamples.html"><a href="surveyexamples.html#metryczka"><i class="fa fa-check"></i><b>5.3.3</b> Metryczka</a></li>
<li class="chapter" data-level="5.3.4" data-path="surveyexamples.html"><a href="surveyexamples.html#weryfikacja-hipotezy-1-1"><i class="fa fa-check"></i><b>5.3.4</b> Weryfikacja hipotezy 1</a></li>
<li class="chapter" data-level="5.3.5" data-path="surveyexamples.html"><a href="surveyexamples.html#weryfikacja-hipotez-24"><i class="fa fa-check"></i><b>5.3.5</b> Weryfikacja hipotez 2–4</a></li>
<li class="chapter" data-level="5.3.6" data-path="surveyexamples.html"><a href="surveyexamples.html#depresja-a-płeć"><i class="fa fa-check"></i><b>5.3.6</b> Depresja a płeć</a></li>
<li class="chapter" data-level="5.3.7" data-path="surveyexamples.html"><a href="surveyexamples.html#depresja-a-staż"><i class="fa fa-check"></i><b>5.3.7</b> Depresja a staż</a></li>
<li class="chapter" data-level="5.3.8" data-path="surveyexamples.html"><a href="surveyexamples.html#depresja-a-rodzaj-miejsca-pracy"><i class="fa fa-check"></i><b>5.3.8</b> Depresja a rodzaj miejsca pracy</a></li>
<li class="chapter" data-level="5.3.9" data-path="surveyexamples.html"><a href="surveyexamples.html#wnioski-1"><i class="fa fa-check"></i><b>5.3.9</b> Wnioski</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="surveyexamples.html"><a href="surveyexamples.html#satysfakcja-przywiązanie-i-zamiar-odejścia"><i class="fa fa-check"></i><b>5.4</b> Satysfakcja, przywiązanie i zamiar odejścia</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="surveyexamples.html"><a href="surveyexamples.html#cel-2"><i class="fa fa-check"></i><b>5.4.1</b> Cel</a></li>
<li class="chapter" data-level="5.4.2" data-path="surveyexamples.html"><a href="surveyexamples.html#metoda-2"><i class="fa fa-check"></i><b>5.4.2</b> Metoda</a></li>
<li class="chapter" data-level="5.4.3" data-path="surveyexamples.html"><a href="surveyexamples.html#wyniki"><i class="fa fa-check"></i><b>5.4.3</b> Wyniki</a></li>
<li class="chapter" data-level="5.4.4" data-path="surveyexamples.html"><a href="surveyexamples.html#wnioski-2"><i class="fa fa-check"></i><b>5.4.4</b> Wnioski</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="surveyexamples.html"><a href="surveyexamples.html#formularze-ankiet"><i class="fa fa-check"></i><b>5.5</b> Formularze ankiet</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="surveyexamples.html"><a href="surveyexamples.html#skala-depresji-becka"><i class="fa fa-check"></i><b>5.5.1</b> Skala Depresji Becka</a></li>
<li class="chapter" data-level="5.5.2" data-path="surveyexamples.html"><a href="surveyexamples.html#ankieta-na-temat-szkodliwości-palenia"><i class="fa fa-check"></i><b>5.5.2</b> Ankieta na temat szkodliwości palenia</a></li>
<li class="chapter" data-level="5.5.3" data-path="surveyexamples.html"><a href="surveyexamples.html#ankieta-satysfakcja-przywiązanie-i-zamiar-odejścia"><i class="fa fa-check"></i><b>5.5.3</b> Ankieta satysfakcja, przywiązanie i zamiar odejścia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="intro2jamovi.html"><a href="intro2jamovi.html"><i class="fa fa-check"></i><b>6</b> Praca z programem Jamovi</a>
<ul>
<li class="chapter" data-level="6.1" data-path="intro2jamovi.html"><a href="intro2jamovi.html#podstawy-pracy-z-jamovi"><i class="fa fa-check"></i><b>6.1</b> Podstawy pracy z Jamovi</a></li>
<li class="chapter" data-level="6.2" data-path="intro2jamovi.html"><a href="intro2jamovi.html#analiza-ankiety-satysfakcja-wiedza-o-paleniu-zamiar-odejścia"><i class="fa fa-check"></i><b>6.2</b> Analiza ankiety satysfakcja – wiedza o paleniu – zamiar odejścia</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="intro2jamovi.html"><a href="intro2jamovi.html#wczytanie-danych"><i class="fa fa-check"></i><b>6.2.1</b> Wczytanie danych</a></li>
<li class="chapter" data-level="6.2.2" data-path="intro2jamovi.html"><a href="intro2jamovi.html#przekodowanie-danych"><i class="fa fa-check"></i><b>6.2.2</b> Przekodowanie danych</a></li>
<li class="chapter" data-level="6.2.3" data-path="intro2jamovi.html"><a href="intro2jamovi.html#wyliczenie-nowych-zmiennych"><i class="fa fa-check"></i><b>6.2.3</b> Wyliczenie nowych zmiennych</a></li>
<li class="chapter" data-level="6.2.4" data-path="intro2jamovi.html"><a href="intro2jamovi.html#analiza-struktury"><i class="fa fa-check"></i><b>6.2.4</b> Analiza struktury</a></li>
<li class="chapter" data-level="6.2.5" data-path="intro2jamovi.html"><a href="intro2jamovi.html#analiza-zależności-zmienne-nominalne"><i class="fa fa-check"></i><b>6.2.5</b> Analiza zależności: zmienne nominalne</a></li>
<li class="chapter" data-level="6.2.6" data-path="intro2jamovi.html"><a href="intro2jamovi.html#analiza-zależności-zmienna-liczbowazmienna-nominalna"><i class="fa fa-check"></i><b>6.2.6</b> Analiza zależności: zmienna liczbowa/zmienna nominalna</a></li>
<li class="chapter" data-level="6.2.7" data-path="intro2jamovi.html"><a href="intro2jamovi.html#analiza-zależności-zmienna-liczbowazmienna-liczbowa-lub-nominalna"><i class="fa fa-check"></i><b>6.2.7</b> Analiza zależności: zmienna liczbowa/zmienna liczbowa lub nominalna</a></li>
<li class="chapter" data-level="6.2.8" data-path="intro2jamovi.html"><a href="intro2jamovi.html#regresja-logistyczna"><i class="fa fa-check"></i><b>6.2.8</b> Regresja logistyczna</a></li>
<li class="chapter" data-level="6.2.9" data-path="intro2jamovi.html"><a href="intro2jamovi.html#redagowanie-raportu"><i class="fa fa-check"></i><b>6.2.9</b> Redagowanie raportu</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="literatura.html"><a href="literatura.html"><i class="fa fa-check"></i>Literatura</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Podstawy statystyki</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="causality" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Analiza współzależności pomiędzy zmiennymi<a href="causality.html#causality" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Pomiędzy zjawiskami występują związki (zależności). Nauki formułują te związki
w postaci <strong>praw</strong>. Jak takie <strong>prawo naukowe</strong> powstaje? Typowo w dwu etapach,
najpierw za pomocą <strong>dedukcji</strong> stawia się <strong>hipotezę</strong>, potem konfrontuje się
hipotezę z danymi (podejście hipotetyczno-dedukcyjne).
Na tym drugim etapie używa się statystyki (lub matematyki, jeżeli prawo ma charakter deterministyczny).</p>
<p>Upraszczając, <em>metoda hypodedukcji</em> sprowadza się do dedukcyjnego sformułowania hipotezy, która następnie jest empirycznie <em>falsyfikowana</em>, tj. próbuje się wykazać, że jest ona nieprawdziwa. Konsekwencje:
nie można dowieść prawdziwości żadnej hipotezy, można natomiast wykazać, że
hipoteza jest fałszywa.</p>
<p>Związki między zmiennymi mogą być albo <strong>funkcyjne</strong> – wartościom jednej zmiennej
odpowiada tylko jedna wartość drugiej zmiennej – albo
<strong>stochastyczne</strong> – wartościom jednej zmiennej odpowiadają z pewnym
przybliżeniem wartości innej zmiennej.</p>
<p>Problem: czy istnieje związek (zależność) pomiędzy cechami?
Przykładowo: czy istnieje związek pomiędzy paleniem (przyczyna)
a chorobą nowotworową (skutek), wiekiem a prawdopodobieństwem zgonu z powodu COVID-19 itd.?</p>
<p>Jaki jest charakter zależności? Jaka jest siła zależności?</p>
<p>Rodzaj konkretnej metody zastosowanej do empirycznej weryfikacji zależy
w szczególności od sposobu pomiaru danych (nominalne, porządkowe, liczbowe),
co pokazano na rysunku <a href="causality.html#fig:metodyAZ">4.1</a>.</p>
<div class="figure"><span style="display:block;" id="fig:metodyAZ"></span>
<img src="DiagramMetod.png" alt="Metody statystycznej weryfikacji zależności pomiędzy zmiennymi" width="99%" />
<p class="caption">
Rysunek 4.1: Metody statystycznej weryfikacji zależności pomiędzy zmiennymi
</p>
</div>
<p>Optymistyczną informacją jest, że metod (oznaczonych krojem pogrubionym na diagramie),
które omawiamy dalej w rozdziale, jest raptem siedem, czyli niedużo.</p>
<div id="dwie-zmienne-nominalne" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Dwie zmienne nominalne<a href="causality.html#dwie-zmienne-nominalne" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="oddsSec" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Ryzyko względne oraz iloraz szans<a href="causality.html#oddsSec" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ryzyko to udział (iloraz) liczby sukcesów do liczby prób (zdarzeń pozytywnych/wyróżnionych do wszystkich).
Zwykle podawany w procentach. Warto zauważyć, że jest to
empiryczny odpowiednik prawdopodobieństwa.</p>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>4.1  </strong></span><strong>Podawanie witaminy C a przeziębienie/brak przeziębienia</strong></p>
<p>Eksperyment, który przeprowadził Linus Pauling (laureat nagrody Nobla
za odkrycie witaminy C),
polegał na tym, że podzielił 280 narciarzy na dwie 140-osobowe grupy.
Przez 5–7 dni podawał witaminę C jednej grupie oraz placebo drugiej grupie.
Obserwował zachorowania na przeziębienie przez następne dwa tygodnie.
Jeden narciarz nie dokończył eksperymentu. Historia milczy, dlaczego tak się stało :-)</p>
<p>W grupie 139 narciarzy, którym podano witaminę C
(grupa C), zachorowało 17. W grupie 140 narciarzy, którym podano placebo (grupa P)
zachorowało 31. Zatem:</p>
<ul>
<li>Ryzyko zachorowania w grupie C wyniosło 17/139 = 12,2%.</li>
<li>Ryzyko zachorowania w grupie P wyniosło 31/140 = 22,14%.</li>
</ul>
<p>Na chłopski rozum: jeżeli witamina C <strong>nie działa</strong>, to powinien
zachorować ten sam odsetek narciarzy w obu grupach.
A tak, jak widać, nie jest.</p>
</div>
<p>Prostymi miarami oceny siły zależności mogą być:</p>
<ul>
<li>różnica ryzyk (<em>risk difference</em>),</li>
<li>ryzyko względne (<em>relative risk</em>) oraz</li>
<li>iloraz szans (<em>odds ratio</em>).</li>
</ul>
<p>Jeżeli <span class="math inline">\(r_e\)</span> oznacza ryzyko w grupie eksperymentalnej (<em>test group</em>, grupa narażona, <em>exposed group</em>),
a <span class="math inline">\(r_k\)</span> w grupie kontrolnej (<em>control group</em>, grupa nienarażona, <em>unexposed group</em>),
to <strong>różnica ryzyk</strong> to po prostu <span class="math inline">\(r_e - r_k\)</span>.
W przykładzie będzie to <span class="math inline">\(22,14 - 12,2 = -9,94\)</span>%
Ta miara, aczkolwiek prosta, jest rzadko stosowana.</p>
<p>Znacznie częściej używa się <strong>ryzyka względnego</strong> definiowanego jako
<span class="math inline">\(RR = r_e/r_k\)</span>. Oczywiste jest, że <span class="math inline">\(RR &lt; 1\)</span> oznacza zmniejszenie
ryzyka; <span class="math inline">\(RR &gt; 1\)</span> oznacza zwiększenie; <span class="math inline">\(RR = 1\)</span> oznacza brak zależności.</p>
<p>Zamiast ryzyka (czyli ilorazu liczby sukcesów do liczby prób) można używać
pojęcia szansa/szansy (<em>odds</em>) definiowanego
jako iloraz sukcesów do porażek.</p>
<p>Jeżeli <span class="math inline">\(o_e\)</span> oznacza szanse w grupie eksperymentalnej
a <span class="math inline">\(o_k\)</span> w grupie kontrolnej, to <strong>iloraz szans</strong> (<em>odds ratio</em>) jest
definiowany jako stosunek <span class="math inline">\(\textrm{OR} = o_e/o_k\)</span>.</p>
<p>Przykładowo jeżeli w dwukrotnym rzucie monetą otrzymano orła i reszkę, to ryzyko
otrzymania orła wynosi 1/2 = 0,5 a szansa otrzymania orła wynosi 1/1 = 1.</p>
<div class="example">
<p><span id="exm:unlabeled-div-22" class="example"><strong>4.2  </strong></span><strong>Narciarze Paulinga (kontynuacja)</strong></p>
<p>Przypomnijmy: ryzyko zachorowania w grupie C wynosi 12,2; ryzyko zachorowania w grupie P
wyniosło 22,14. Ryzyko względne wynosi zatem <span class="math inline">\(12,2/22,14 = 0,55\)</span>.
Podanie witaminy C zmniejsza ryzyko zachorowania o prawie połowę.</p>
<p>Szansa, że narciarz z grupy C zachoruje, wynosi 17/122 = 13,9%.
Szansa, że narciarz w grupie P zachoruje, wynosi 28,44%.</p>
<p>Zatem iloraz szans
dla narciarzy wyniesie 13,9/28,44 = 0,48.
Podanie witaminy C zmniejsza szansę na zachorowanie o ponad połowę.
Albo 1/0,48 = 2,04, co oznacza, że narciarz, który nie brał witaminy C, ma
ponaddwukrotnie większą szansę na zachorowanie.</p>
<p>Jak widać, dla dużych ryzyk (rzut monetą) szansa
różni się znacznie od prawdopodobieństwa, ale dla małych ryzyk obie miary mają zbliżoną wartość.</p>
</div>
<p>Właściwości ilorazu szans:</p>
<ul>
<li>jeżeli równe 1, to sukces/porażka równie prawdopodobne;</li>
<li>jeżeli większe od 1, to sukces jest bardziej prawdopodobny;</li>
<li>jeżeli jest mniejsze od 1, to porażka jest bardziej prawdopodobna.</li>
</ul>
<p>Dane w badaniach wykorzystujących ryzyko/szanse mają często postać
następującej tabeli dwudzielnej o wymiarach <span class="math inline">\(2\times 2\)</span>
(a, b, c i d to liczebności):</p>
<table>
<thead>
<tr class="header">
<th>Grupa</th>
<th>sukces</th>
<th>porażka</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>grupa kontrolna</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>grupa eksperymentalna</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>
<p>Dla danych w tej postaci:</p>
<p><span class="math display">\[\begin{align}
\textrm{RR} &amp;= (a/(a+b))/(c/(c+d))\nonumber \\
\textrm{OR} &amp;= (ad)/(bc) \nonumber
\end{align}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-23" class="example"><strong>4.3  </strong></span><strong>Narciarze Paulinga (tabela dwudzielna)</strong></p>
<table>
<thead>
<tr class="header">
<th>Grupa</th>
<th>katar</th>
<th>zdrowy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>grupa C</td>
<td>17</td>
<td>122</td>
</tr>
<tr class="even">
<td>grupa P</td>
<td>31</td>
<td>109</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\textrm{RR} = (17/(17 + 122))/(31/(31 + 109)) = 0,55\)</span> oraz</p>
<p><span class="math inline">\(\textrm{OR} = (17 \cdot 109)/(31 \cdot 122) =0,48\)</span></p>
<p>Otrzymaliśmy oczywiście identyczny wynik jak w poprzednim przykładzie.</p>
</div>
</div>
<div id="przedziały-ufności-dla-ryzyka-względnego-i-ilorazu-szans" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Przedziały ufności dla ryzyka względnego i ilorazu szans<a href="causality.html#przedziały-ufności-dla-ryzyka-względnego-i-ilorazu-szans" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ryzyko, ryzyko względne czy iloraz szans to parametry podobne do odsetka kobiet
wśród kandydatów na radnych z przykładu w poprzednim rozdziale. Wiemy,
że estymatorem punktowym proporcji jest proporcja z próby. Nie będzie
wielkim odkryciem, że estymatorem punktowym ryzyka jest ryzyko z próby,
ryzyka względnego/ilorazu szans zaś ryzyko względne/iloraz szans z próby.</p>
<p>Standardem jest obliczanie dla ryzyka względnego oraz ilorazu szans
oprócz ocen punktowych także
przedziałów ufności czyli podawania dwóch wartości, pomiędzy którymi
z zadanym prawdopodobieństwem znajduje się nieznana wartość szacowanego
parametru.</p>
<div class="example">
<p><span id="exm:unlabeled-div-24" class="example"><strong>4.4  </strong></span><strong>Narciarze Paulinga (przedziały ufności)</strong></p>
<p>Końce przedziałów ufności dla ilorazu szans (ocena punktowa 0,4899524) wynoszą:
[0,2569389; 0,934282] zaś dla
ryzyka względnego (ocena punktowa 0,5523323) przedział ufności wynosi [0,3209146; 0,9506298].</p>
</div>
<p><strong>Uwaga</strong>: nie jest specjalnie istotne, jaka jest konkretna formuła obliczania
przedziałów ufności, przecież obliczenia i tak koniec końców wykona
program komputerowy.</p>
<p>Przedział ufności dla ilorazu szans nie zawiera 1;
zatem branie witaminy C zmniejsza szanse na zachorowanie;
albo zwiększa szanse na niezachorowanie od <span class="math inline">\(1/0,25 = 4\)</span> do <span class="math inline">\(1/0,9 \approx 1,1\)</span>. Żeby
to zabrzmiało ładnie i po polsku: zwiększa szanse na niezachorowanie od 10% do 300%.</p>
<p>Dlaczego taka znacząca rozpiętość? Bo próba jest względnie mała. Gdyby
Pauling zwerbował nie 280, a 2800 narciarzy, mógłby weryfikować działanie
swojej witaminy z większą pewnością.</p>
</div>
<div id="tabele-wielodzielne" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Tabele wielodzielne<a href="causality.html#tabele-wielodzielne" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Łączny rozkład dwóch lub większej liczby zmiennych można przedstawić
w tabeli. Taka tabela nazywa się dwudzielna (dla dwóch zmiennych)
lub wielodzielna albo wielodzielcza (dla więcej niż dwóch zmiennych).
Inne nazwy dla tabel wielodzielnych to krzyżowe albo kontyngencji
(<em>cross-tabulation</em>, <em>contingency</em> albo <em>two-way tables</em>).</p>
<p>Ograniczmy się do analizy tabel dwudzielnych.</p>
<div class="example">
<p><span id="exm:unlabeled-div-25" class="example"><strong>4.5  </strong></span><strong>Narciarze Paulinga (kontynuacja)</strong></p>
<p>Eksperyment Paulinga można przedstawić w postaci następującej tablicy dwudzielnej:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">zdrowy</th>
<th align="right">katar</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">grupa C</td>
<td align="right">122</td>
<td align="right">17</td>
<td align="right">139</td>
</tr>
<tr class="even">
<td align="left">grupa P</td>
<td align="right">109</td>
<td align="right">31</td>
<td align="right">140</td>
</tr>
<tr class="odd">
<td align="left">razem</td>
<td align="right">231</td>
<td align="right">48</td>
<td align="right">279</td>
</tr>
</tbody>
</table>
<p>Taka tabela składa się z wierszy i kolumn.
Dolny wiersz zawiera łączną liczebność dla wszystkich wierszy w danej kolumnie.
Podobnie prawa skrajna kolumna zawiera łączną
liczebność dla wszystkich kolumn dla danego wiersza. Dolny wiersz/prawą
kolumnę nazywamy <strong>rozkładami brzegowymi</strong>. Rozkłady brzegowe przestawiają
rozkłady każdej zmiennej osobno.</p>
<p>Pozostałe kolumny oraz wiersze nazywane
są <strong>rozkładami warunkowymi</strong>. Rozkładów warunkowych jest tyle, ile
wynosi suma <span class="math inline">\(r + c\)</span>, gdzie <span class="math inline">\(r\)</span> to liczba wariantów jednej cechy,
a <span class="math inline">\(c\)</span> to liczba wariantów drugiej cechy.</p>
<p>Przy warunku, że narciarz brał witaminę C, 122 takich osób
nie zachorowało, a 17 zachorowało.
Drugi rozkład warunkowy: 109 narciarzy, którzy brali placebo,
nie zachorowało, a 31 zachorowało. Są także rozkłady
warunkowe dla drugiej cechy. W grupie narciarzy, którzy zachorowali,
122 brało witaminę C, a 109 brało placebo.
W grupie narciarzy, którzy nie zachorowali,
109 brało witaminę C, a 31 brało placebo.
Rozkłady warunkowe są cztery, bo obie cechy mają po dwa warianty. Jest
to najmniejsza możliwa tabela wielodzielna.</p>
<p>Zamiast liczebności można posługiwać się odsetkami (procentami):</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">zdrowy</th>
<th align="right">katar</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">grupa C</td>
<td align="right">43,73</td>
<td align="right">6,09</td>
<td align="right">49,82</td>
</tr>
<tr class="even">
<td align="left">grupa P</td>
<td align="right">39,07</td>
<td align="right">11,11</td>
<td align="right">50,18</td>
</tr>
<tr class="odd">
<td align="left">razem</td>
<td align="right">82,80</td>
<td align="right">17,20</td>
<td align="right">100,00</td>
</tr>
</tbody>
</table>
<p>Narciarze, którzy brali witaminę C oraz nie zachorowali, stanowią
43,73%
wszystkich narciarzy. Mało przydatne…</p>
<p>Ciekawsze jest obliczenie procentów każdego wiersza osobno, tj. dzielimy
liczebności w każdej kolumnie przez liczebności rozkładu brzegowego (wartości
ostatniej kolumny):</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">zdrowy</th>
<th align="right">katar</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">grupa C</td>
<td align="right">87,77</td>
<td align="right">12,23</td>
<td align="right">100</td>
</tr>
<tr class="even">
<td align="left">grupa P</td>
<td align="right">77,86</td>
<td align="right">22,14</td>
<td align="right">100</td>
</tr>
<tr class="odd">
<td align="left">razem</td>
<td align="right">82,80</td>
<td align="right">17,20</td>
<td align="right">100</td>
</tr>
</tbody>
</table>
<p>Otrzymaliśmy ryzyka zachorowania na katar (lub nie zachorowania). Ryzyko
zachorowania dla całej grupy wynosi
17,2%, a ryzyko niezachorowania
to 82,8%. Jest, przyznajmy, całkiem <strong>zdroworozsądkowym założeniem</strong>
(uczenie hipotezą statystyczną), że jeżeli przyjmowanie witaminy nie ma związku
z zachorowaniem lub nie na katar, to w grupie tych, którzy brali, i tych, którzy nie brali,
powinniśmy mieć identyczne rozkłady warunkowe równe rozkładowi brzegowemu.
Czyli powinno przykładowo zachorować
17,2% narciarzy, którzy
brali witaminę C, a widzimy, że zachorowało
jedynie 12,23%.</p>
<p>Na oko księgowego witamina C działa (bo są różnice), ale dla statystyka liczy się to,
czy ta różnica jest na tyle duża, że (z założonym prawdopodobieństwem)
można wykluczyć działanie przypadku.</p>
<p>Rozumowanie jest następujące: jeżeli prawdopodobieństwo wystąpienia
tak dużej różnicy jest małe, to cechy nie są niezależne.
Jest to istota i jedyny wniosek z czegoś, co się nazywa
testem niezależności chi-kwadrat.
Test chi-kwadrat porównuje liczebności tablicy wielodzielnej z idealną tablicą wielodzielną,
która zakłada niezależność jednej zmiennej od drugiej.</p>
<p>Można udowodnić, że taka idealna tablica powstanie przez przemnożenie dla
każdego elementu tablicy odpowiadających mu wartości brzegowych,
a następnie podzieleniu tego przez łączną liczebność (czyli przykładowo pierwszy
element poniższej „idealnej” tablicy to 231 pomnożone przez
139 i podzielone przez 279; proszę
sprawdzić,
że jest to 115,086):</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">zdrowy</th>
<th align="right">katar</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">grupa C</td>
<td align="right">115,086</td>
<td align="right">23,914</td>
<td align="right">139</td>
</tr>
<tr class="even">
<td align="left">grupa P</td>
<td align="right">115,914</td>
<td align="right">24,086</td>
<td align="right">140</td>
</tr>
<tr class="odd">
<td align="left">razem</td>
<td align="right">231,000</td>
<td align="right">48,000</td>
<td align="right">279</td>
</tr>
</tbody>
</table>
<p>Warto
zwrócić uwagę, że <strong>rozkłady brzegowe</strong> są identyczne, identyczna
jest też łączna liczebność. Różnią się tylko rozkłady warunkowe (które nie są
liczbami całkowitymi, ale tak ma być i nie jest to błąd).</p>
<p>Za pomocą testu chi-kwadrat obliczamy prawdopodobieństwo wystąpienia
tak dużych lub większych różnic. Wynosi ono 0,0419.
Czyli wystąpienie tak dużych różnic
pomiędzy <strong>oczekiwanymi</strong> (przy założeniu o niezależności zmiennych)
a obserwowanymi liczebnościami zdarza się około 4 razy na 100.</p>
</div>
<p>Jeszcze raz przypominamy ideę testu: jeżeli prawdopodobieństwo zaobserwowanych
różnic jest małe, to zakładamy, że:</p>
<ul>
<li><p>albo mamy pecha i pięć razy podrzucając monetą, zawsze nam spadła
reszka (prawdopodobieństwo około 0,03), albo</p></li>
<li><p>że założenie co do niezależności jest fałszywe.</p></li>
</ul>
<p>Statystyk zawsze wybierze
drugie. Pozostaje tylko ustalenie, co to znaczy <strong>małe</strong>.</p>
<p>Małe to takie, które jest mniejsze od arbitralnie przyjętego
przez statystyka. Zwykle jest to 0,05 lub 0,01 (czasami 0,1),
co oznacza, że odrzucając założenie o braku związku pomiędzy
katarem a braniem witaminy C, pomylimy się pięć razy lub raz na 100.</p>
<p><strong>Uwaga</strong>: proszę zwrócić uwagę że wniosek z testu niezależności jest
słabszy niż z porównania ryzyk. Tam mamy informację że zależność istnieje
i oszacowaną jej wielkość (np. za pomocą ryzyka względnego) tutaj tylko
zweryfikowaliśmy fakt, czy obie zmienne są niezależne, czy nie.</p>
<div class="example">
<p><span id="exm:unlabeled-div-26" class="example"><strong>4.6  </strong></span><strong>Palenie a status społeczno-ekonomiczny</strong></p>
<p>Dla pewnej grupy osób odnotowujemy ich status-społeczno-ekonomiczny
(wysoki/<strong>high</strong>, średni/<strong>middle</strong>, niski/<strong>low</strong>)
oraz status-względem-palenia
(wartości: pali/<strong>current</strong>, palił-nie-pali/<strong>former</strong>, nigdy-nie-palił/<strong>never</strong>).
Obie zmienne są nominalne, obie mają po trzy wartości. Można
sklasyfikować wszystkich badanych w następujący sposób:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">High</th>
<th align="right">Low</th>
<th align="right">Middle</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">current</td>
<td align="right">51</td>
<td align="right">43</td>
<td align="right">22</td>
<td align="right">116</td>
</tr>
<tr class="even">
<td align="left">former</td>
<td align="right">92</td>
<td align="right">28</td>
<td align="right">21</td>
<td align="right">141</td>
</tr>
<tr class="odd">
<td align="left">never</td>
<td align="right">68</td>
<td align="right">22</td>
<td align="right">9</td>
<td align="right">99</td>
</tr>
<tr class="even">
<td align="left">razem</td>
<td align="right">211</td>
<td align="right">93</td>
<td align="right">52</td>
<td align="right">356</td>
</tr>
</tbody>
</table>
<p>Uwaga: status-społeczno-ekonomiczny, to miara prestiżu używana w socjologii
(można na Wikipedii doczytać, co to dokładnie jest).</p>
<p>Tym razem tabela składa się z trzech wierszy i trzech kolumn (ostatni wiersz/kolumna się
nie liczą, bo to są sumy – rozkłady brzegowe).</p>
<p>Przedstawmy tę tabelę w postaci udziałów procentowych sumujących się
dla każdego wiersza osobno do 100% (tj. dzielimy
liczebności w każdej kolumnie przez liczebności rozkładu brzegowego (wartości
ostatniej kolumny):</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">High</th>
<th align="right">Low</th>
<th align="right">Middle</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">current</td>
<td align="right">43,97</td>
<td align="right">37,07</td>
<td align="right">18,97</td>
<td align="right">100</td>
</tr>
<tr class="even">
<td align="left">former</td>
<td align="right">65,25</td>
<td align="right">19,86</td>
<td align="right">14,89</td>
<td align="right">100</td>
</tr>
<tr class="odd">
<td align="left">never</td>
<td align="right">68,69</td>
<td align="right">22,22</td>
<td align="right">9,09</td>
<td align="right">100</td>
</tr>
<tr class="even">
<td align="left">razem</td>
<td align="right">59,27</td>
<td align="right">26,12</td>
<td align="right">14,61</td>
<td align="right">100</td>
</tr>
</tbody>
</table>
<p>Rozumowanie jest identyczne jak dla narciarzy Paulinga. Jeżeli nie ma zależności
pomiędzy paleniem a statusem, to procenty w ostatnim wierszu powinny
być identyczne jak w wierszach 1–3 (nagłówka nie liczymy). Tym idealnym
procentom odpowiadają następujące liczebności:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">High</th>
<th align="right">Low</th>
<th align="right">Middle</th>
<th align="right">razem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">current</td>
<td align="right">68,75281</td>
<td align="right">30,30337</td>
<td align="right">16,94382</td>
<td align="right">116</td>
</tr>
<tr class="even">
<td align="left">former</td>
<td align="right">83,57022</td>
<td align="right">36,83427</td>
<td align="right">20,59551</td>
<td align="right">141</td>
</tr>
<tr class="odd">
<td align="left">never</td>
<td align="right">58,67697</td>
<td align="right">25,86236</td>
<td align="right">14,46067</td>
<td align="right">99</td>
</tr>
<tr class="even">
<td align="left">razem</td>
<td align="right">211,00000</td>
<td align="right">93,00000</td>
<td align="right">52,00000</td>
<td align="right">356</td>
</tr>
</tbody>
</table>
<p>Wartość prawdopodobieństwa dla testu chi-kwadrat określająca, że przy założeniu
niezależności obu zmiennych tak duża różnica między liczebnościami rzeczywistymi a idealnymi
(porównaj stosowne tabele wyżej) jest dziełem przypadku wynosi 0,001.
Jest to prawdopodobieństwo tak małe, że statystyk odrzuca założenie o niezależności
statusu i palenia (myląc się w przybliżeniu 0,001 ≈ raz na tysiąc).</p>
</div>
</div>
</div>
<div id="zmienna-liczbowa-i-zmienna-nominalna" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Zmienna liczbowa i zmienna nominalna<a href="causality.html#zmienna-liczbowa-i-zmienna-nominalna" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Obserwujemy wartości zmiennej liczbowej <strong>w grupach</strong> określonych przez wartości zmiennej nominalnej,
np. wypalenie zawodowe w podziale na miejsce pracy. Grup może być dwie lub więcej.</p>
<p>Stawiamy hipotezę, że wartości zmiennej w każdej grupie są równe, wobec hipotezy alternatywnej,
że tak nie jest (że są różne jeżeli grup jest dwie; co najmniej jedna jest różna jeżeli grup jest
więcej niż dwie). Stosujemy odpowiedni test statystyczny:</p>
<ul>
<li><p>jeżeli liczba grup wynosi 2 oraz można przyjąć założenie o przybliżonej
normalności rozkładów, to stosujemy test <span class="math inline">\(t\)</span> Welcha;</p></li>
<li><p>jeżeli liczba grup wynosi 2, ale nie można założyć normalności
rozkładów, to stosujemy test U-Manna-Whitneya;</p></li>
<li><p>jeżeli liczba grup jest większa niż dwie oraz można przyjąć założenie
o normalności rozkładów, to stosujemy test ANOVA z poprawką Welcha;</p></li>
<li><p>jeżeli liczba grup jest większa od dwóch oraz nie można przyjąć założenia
o normalności rozkładów, to stosujemy test Kruskala-Wallisa.</p></li>
</ul>
<p>W postaci diagramu ze strzałkami przedstawiono to na rysunku <a href="causality.html#fig:testy">4.2</a>.</p>
<div class="figure"><span style="display:block;" id="fig:testy"></span>
<img src="TestFlowChart.png" alt="Testowanie istotności różnicy pomiędzy średnimi" width="80%" />
<p class="caption">
Rysunek 4.2: Testowanie istotności różnicy pomiędzy średnimi
</p>
</div>
<p>Każdy z testów jest interpretowany identycznie:</p>
<ol style="list-style-type: decimal">
<li><p>Obliczana jest wartość statystyki testu <span class="math inline">\(t_k\)</span>.</p></li>
<li><p>Obliczane jest prawdopodobieństwo <span class="math inline">\(t \geq t_k\)</span> czyli przyjęcia przez
statystykę testu <span class="math inline">\(t\)</span> równej lub większej od <span class="math inline">\(t_k\)</span> (co do wartości bezwzględnej).
To prawdopodobieństwo zwyczajowo oznacza się literą p albo p-value (czyli „wartość p”).</p></li>
<li><p>Jeżeli p jest mniejsze/równe od przyjętego poziomu istotności, to hipotezę zerową odrzucamy;
jeżeli p jest większe od przyjętego poziomu istotności, to nie ma podstaw do odrzucenia
hipotezy zerowej.</p></li>
</ol>
<p>Odrzucenie hipotezy zerowej oznacza, że istnieje związek pomiędzy jedną a drugą zmienną.
Jeżeli nie ma podstaw do odrzucenia
hipotezy zerowej, to oznacza to, że takiej zależności nie udało nam się wykazać.</p>
<p>Omawiając wynik, należy podać wartość <span class="math inline">\(t_k\)</span> oraz p. Statystyka testu może się
różnie nazywać i być oznaczana różnym symbolem,
np.: t (test t Welcha), U (test U Manna-Whitneya).</p>
<p>Testy <span class="math inline">\(t\)</span> Welcha oraz ANOVA są <strong>parametryczne</strong>, porównujemy średnie w grupach.
Testy U-Manna-Whitneya oraz Kruskala-Wallisa są <strong>nieparametryczne</strong>, bo porównujemy
rozkłady wartości zmiennej w grupach.</p>
<div id="test-t-welcha" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Test <span class="math inline">\(t\)</span> Welcha<a href="causality.html#test-t-welcha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Test stosujemy, jeżeli porównujemy dwie grupy oraz można przyjąć
założenie, że rozkład wartości w obu grupach jest normalny.
Test <span class="math inline">\(t\)</span> Welcha jest testem parametrycznym. Sprawdzamy, czy średnie w grupach są równe.</p>
<div class="example">
<p><span id="exm:unlabeled-div-27" class="example"><strong>4.7  </strong></span><strong>Poziom depresji a miejsce pracy</strong></p>
<p>Studenci pielęgniarstwa i ratownictwa PSW w 2023 roku wypełnili
ankietę zawierającą
test depresji Becka, mierzący <strong>poziom depresji</strong> (wartość liczbowa),
oraz pytanie o rodzaj miejsca pracy (skala nominalna). Poniżej
zestawiono średnie wartości <strong>poziomu depresji</strong> w podziale
na rodzaj miejsca pracy (szpital/przychodnia).</p>
<table>
<thead>
<tr class="header">
<th align="left">m-pracy</th>
<th align="right">średnia</th>
<th align="right">mediana</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Przychodnia</td>
<td align="right">7,833333</td>
<td align="right">7</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">Szpital</td>
<td align="right">13,252747</td>
<td align="right">11</td>
<td align="right">91</td>
</tr>
</tbody>
</table>
<p>Kolumna n zawiera liczebności.</p>
<p>Średnie różnią się
o 5,42.
Pytanie: czy to dużo czy mało?</p>
<p>Przyjmijmy (na razie bez sprawdzania), że rozkłady wartości poziomu depresji
w obu grupach są
normalne. Można zatem zastosować test <span class="math inline">\(t\)</span> Welcha.</p>
<table>
<thead>
<tr class="header">
<th align="left">Grupa1</th>
<th align="left">Grupa2</th>
<th align="right">n1</th>
<th align="right">n2</th>
<th align="right">t</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Przychodnia</td>
<td align="left">Szpital</td>
<td align="right">12</td>
<td align="right">91</td>
<td align="right">-2,895988</td>
<td align="right">0,00978</td>
</tr>
</tbody>
</table>
<p>Kolumna t zawiera wartość statystyki testu <span class="math inline">\(t_k\)</span>. Kolumna p
zawiera oczywiście wartość prawdopodobieństwa p.</p>
<p>Ponieważ wartość <span class="math inline">\(p\)</span> równa 0,00978 jest mniejsza od każdego zwyczajowo
przyjmowanego poziomu istotności (np. 0,05 albo 0,1), hipotezę, że średnie w obu grupach są równe,
należy odrzucić.
W konsekwencji stwierdzamy, że poziom depresji pracujących w szpitalu
był istotnie wyższy od pracujących w przychodni.</p>
</div>
</div>
<div id="testowanie-normalności" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Testowanie normalności<a href="causality.html#testowanie-normalności" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Statystyk nie przyjmuje założeń na słowo honoru.
Kiedy zatem można przyjąć założenie o normalności a kiedy nie?
Można to ocenić na podstawie wykresu kwantylowego oraz
posługując się testem Shapiro-Wilka
(bo statystycy na każde pytanie mają zawsze <strong>jakiś</strong> stosowny test).</p>
<div class="example">
<p><span id="exm:unlabeled-div-28" class="example"><strong>4.8  </strong></span><strong>Poziom depresji a miejsce pracy</strong></p>
<p>Hipoteza zerowa w teście Shapiro-Wilka (S-W) zakłada, że rozkład cechy
jest normalny.
Interpretacja tego testu jest „standardowa“, mianowicie małe wartości <span class="math inline">\(p\)</span>
świadczą przeciwko hipotezie zerowej.</p>
<table>
<thead>
<tr class="header">
<th align="left">m-pracy</th>
<th align="right">S-W</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Przychodnia</td>
<td align="right">0,9256178</td>
<td align="right">0,3359655</td>
</tr>
<tr class="even">
<td align="left">Szpital</td>
<td align="right">0,8191903</td>
<td align="right">0,0000000</td>
</tr>
</tbody>
</table>
<p>Kolumna S-W zawiera oczywiście wartości statystyki testu S-W.</p>
<p>Rozkład w grupie <code>szpital</code> nie jest normalny (o czym świadczy niska wartość p).
Nasze założenie co do normalności
było niepoprawne i należy do weryfikacji hipotezy o równości wartości zmiennej w grupach
zamiast testu <span class="math inline">\(t\)</span> Welcha zastosować test U Manna-Whitneya.</p>
<p>Wykres kwantylowy jest graficzną metodą weryfikacji normalności rozkładu
zmiennej. Dla <strong>poziomu depresji</strong> wygląda jak na poniższym rysunku:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>Prosta odpowiada teoretycznym wartościom kwantyli rozkładu poziomu depresji przy założeniu,
że mają one rozkład normalny. Punkty odpowiadają zaobserwowanym wartościom kwantyli.
Im bardziej punkty nie pokrywają się z prostą
(zwłaszcza na skrajach rozkładu), tym mniej wierzymy, że rozkład jest normalny.</p>
<p>W tym przypadku wygląda, że rozkład w grupie Szpital <strong>nie jest</strong> normalny.
W grupie Przychodnia jest lepiej, ale jednocześnie to lepiej jest mało wiarygodne
z uwagi na małą liczebność grupy (zaledwie 12 obserwacji).</p>
</div>
</div>
<div id="test-u-manna-whitneya" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Test U Manna-Whitneya<a href="causality.html#test-u-manna-whitneya" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Test U Manna-Whitneya jest testem nieparametrycznym. Sprawdzamy, czy rozkłady
zmiennej w grupach są identyczne.</p>
<div class="example">
<p><span id="exm:unlabeled-div-29" class="example"><strong>4.9  </strong></span><strong>Poziom depresji a miejsce pracy</strong></p>
<p>Ponieważ grup jest dokładnie 2, a rozkład nie jest normalny, stosujemy test U Manna-Whitneya.</p>
<table>
<thead>
<tr class="header">
<th align="left">Grupa1</th>
<th align="left">Grupa2</th>
<th align="right">n1</th>
<th align="right">n2</th>
<th align="right">U</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Przychodnia</td>
<td align="left">Szpital</td>
<td align="right">12</td>
<td align="right">91</td>
<td align="right">317</td>
<td align="right">0,0185</td>
</tr>
</tbody>
</table>
<p>Prawdopodobieństwo wystąpienia tak dużej wartości statystyki testu (U) przy założeniu, że
rozkłady zmiennej w obu grupach
są identyczne, wynosi 0,0185. Różnica jest zatem istotna na każdym zwyczajowo
przyjmowanym poziomie istotności (np. 0,05 albo 0,1); oba rozkłady różnią się.
Kolumna U zawiera wartość statystyki testu U. Przypominamy, że
dobry zwyczaj nakazuje podawać tę wartość, omawiając wynik testu, dlatego to czynimy.</p>
<p>Depresja wśród pracowników szpitali jest wyższa niż wśród pracowników
przychodni (w przypadku testu U Manna-Whitneya porównujemy wartości mediany).</p>
</div>
</div>
<div id="test-anova" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Test ANOVA<a href="causality.html#test-anova" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jeżeli liczba grup jest większa niż dwie, ale można przyjąć założenie,
że w każdej grupie zmienna ma rozkład normalny, to stosujemy test ANOVA z poprawką Welcha.
Test ANOVA jest testem parametrycznym.
Sprawdzamy, czy średnie we wszystkich grupach są równe.</p>
<div class="example">
<p><span id="exm:unlabeled-div-30" class="example"><strong>4.10  </strong></span><strong>Poziom depresji a staż pracy</strong></p>
<p>W ankiecie, którą wypełnili
studenci pielęgniarstwa i ratownictwa PSW w 2023 roku,
było też pytanie o staż pracy. Oryginalną liczbową wartość zmiennej
staż zamieniono na zmienną w skali nominalnej o następujących
czterech wartościach: <code>&lt;6</code> (oznacza od 0 do 6 lat stażu pracy), <code>07-12</code> (7–12 lat), <code>13-18</code> (13–18 lat)
oraz <code>&gt;19</code> (19 i więcej lat).</p>
<table>
<thead>
<tr class="header">
<th align="left">staż (kategoria)</th>
<th align="right">średnia</th>
<th align="right">mediana</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">&lt;06</td>
<td align="right">12,84615</td>
<td align="right">11,0</td>
<td align="right">39</td>
</tr>
<tr class="even">
<td align="left">07-12</td>
<td align="right">12,14286</td>
<td align="right">9,0</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left">13-18</td>
<td align="right">10,91667</td>
<td align="right">6,5</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">&gt;19</td>
<td align="right">12,95556</td>
<td align="right">11,0</td>
<td align="right">45</td>
</tr>
</tbody>
</table>
<p>Zakładając, że rozkłady w grupach są normalne, do weryfikacji hipotezy
o równości wszystkich średnich możemy zastosować test ANOVA z poprawką Welcha.
Na poniższym wydruku wartość statystyki testu jest oznaczona jako <code>F</code>,
a wartość p symbolem <code>p-value</code>:</p>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  P and staz
## F = 0,14844, num df = 3,000, denom df = 20,847, p-value = 0,9295</code></pre>
<p>Wartość p równa 0,9295 świadczy o tym, że nie ma istotnych różnic pomiędzy średnimi, co oznacza,
że pomiędzy poziomem depresji a kategoriami stażu pracy nie ma zależności.</p>
<p>Czy zastosowanie testu ANOVA było poprawne? Żeby się o tym przekonać, trzeba
zastosować (znowu) test Shapiro-Wilka:</p>
<table>
<thead>
<tr class="header">
<th align="left">m-pracy</th>
<th align="right">S-W</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">&lt;06</td>
<td align="right">0,9127826</td>
<td align="right">0,0052385</td>
</tr>
<tr class="even">
<td align="left">07-12</td>
<td align="right">0,8939017</td>
<td align="right">0,2956402</td>
</tr>
<tr class="odd">
<td align="left">13-18</td>
<td align="right">0,8138678</td>
<td align="right">0,0135286</td>
</tr>
<tr class="even">
<td align="left">&gt;19</td>
<td align="right">0,7239373</td>
<td align="right">0,0000001</td>
</tr>
</tbody>
</table>
<p>Wobec takiego wyniku testu do oceny istotności różnic
należy zastosować bardziej ogólny test Kruskala-Wallisa.</p>
</div>
</div>
<div id="test-kruskala-wallisa" class="section level3 hasAnchor" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> Test Kruskala-Wallisa<a href="causality.html#test-kruskala-wallisa" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Test Kruskala-Wallisa jest testem nieparametrycznym. Sprawdzamy, czy rozkłady zmiennej
w grupach są identyczne.</p>
<div class="example">
<p><span id="exm:unlabeled-div-31" class="example"><strong>4.11  </strong></span><strong>Poziom depresji a staż pracy</strong></p>
<p>Na poniższym wydruku wartość statystyki testu jest oznaczona jako
<code>Kruskal-Wallis chi-squared</code>, a wartość p symbolem <code>p-value</code>:</p>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  P by staz
## Kruskal-Wallis chi-squared = 2,6982, df = 3, p-value = 0,4405</code></pre>
<p>Prawdopodobieństwo tak dużej wartości statystyki testu
przy założeniu, że rozkłady wartości zmiennej we wszystkich grupach są identyczne, wynosi
0,4405 (różnice są zatem nieistotne; wszystkie rozkłady są identyczne i nie ma zależności).</p>
</div>
</div>
</div>
<div id="dwie-zmienne-liczbowe" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Dwie zmienne liczbowe<a href="causality.html#dwie-zmienne-liczbowe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="korelacyjny-wykres-rozrzutu" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Korelacyjny wykres rozrzutu<a href="causality.html#korelacyjny-wykres-rozrzutu" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wykres rozrzutu (<em>scatter plot</em>), znany także jako korelogram albo wykres XY,
to prosty wykres kreślony w układzie kartezjańskim, w którym każdej obserwacji
(składającej się z dwóch liczb) odpowiada kropka o współrzędnych XY.</p>
<p>O występowaniu związku świadczy układanie się kropek według jakiegoś
kształtu (krzywej). O braku związku
świadczy chmura punktów niepodobna do żadnej krzywej.</p>
<p>Punkty układające się według prostej świadczą o zależności liniowej
(wyjątek: linia pozioma lub pionowa o czym dalej), zaś
punkty układające się według krzywej świadczą
o zależności nieliniowej.</p>
<div class="example">
<p><span id="exm:unlabeled-div-32" class="example"><strong>4.12  </strong></span><strong>Zamożność a konsumpcja mięsa</strong></p>
<p>Organizacja Narodów Zjednoczonych do spraw Wyżywienia i Rolnictwa znana jako FAO
udostępnia dane dotyczące konsumpcji żywności
na świecie (<a href="https://www.fao.org/faostat/en/#home" class="uri">https://www.fao.org/faostat/en/#home</a>). Bank Światowy
udostępnia dane dotyczące dochodu narodowego (<a href="https://data.worldbank.org/" class="uri">https://data.worldbank.org/</a>).</p>
<p>Konsumpcja mięsa jest mierzona jako średnia roczna konsumpcja w kilogramach na mieszkańca w każdym kraju (<em>per capita</em>).
Dochód zaś jest mierzony jako średni dochód w tysiącach dolarów na mieszkańca w każdym kraju (<em>per capita</em>).
Dane dotyczą roku 2013.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="90%" /></p>
<p>Przy dużej dozie wyobraźni można dostrzec relację liniową pomiędzy
konsumpcją mięsa a GDP, co oznaczono na wykresie linią prostą. Można też założyć, że
relacja pomiędzy konsumpcją mięsa a GDP ma charakter nieliniowy (linia krzywa).
Relacja, niezależnie od tego,
czy jest liniowa, czy nieliniowa,
jest na pewno mocno przybliżona,
co stanowi najbardziej pewny wniosek,
który można wysnuć z wykresu rozrzutu.</p>
</div>
</div>
<div id="PearsonCoeff" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Pomiar siły zależności: współczynnik korelacji liniowej Pearsona<a href="causality.html#PearsonCoeff" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Kowariancja to średnia arytmetyczna iloczynów odchyleń wartości zmiennych <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>
od ich wartości średnich. Dla <span class="math inline">\(n\)</span> obserwacji na zmiennych <span class="math inline">\(X\)</span> oraz <span class="math inline">\(Y\)</span>
można to zapisać w postaci następującej formuły:</p>
<p><span class="math display">\[\mathrm{cov} (xy) = \frac{1}{n} \left( (x_1 - \bar x)\cdot (y_1 - \bar y)  + ... +
(x_n- \bar x)\cdot (y_n - \bar y) \right)\]</span></p>
<p>Kowariancja zależy od rozproszenia (im większe, tym większa),
ma też dziwną jednostkę (jednostkaX · jednostkaY) oraz zależy
od wybranych skal (np. tony vs gramy).</p>
<p>Z tych powodów do pomiaru związku pomiędzy cechami używa się
standaryzowanego współczynnika kowariancji,
zwanego <strong>współczynnikiem korelacji liniowej Pearsona</strong> (<em>Pearson
correlation coefficient</em>). Standaryzacja polega na podzieleniu wartości
kowariancji przez iloczyn odchyleń standardowych <span class="math inline">\(s_x\)</span> oraz <span class="math inline">\(s_y\)</span>.</p>
<p><span class="math display">\[r_{xy} = \frac{\mathrm{cov}(xy) }{s_x \cdot s_y}\]</span></p>
<p>Współczynnik jest miarą niemianowaną, przyjmującą wartości ze zbioru <span class="math inline">\([-1;1]\)</span>;
Skrajne wartości <span class="math inline">\(\pm 1\)</span>
świadczą o związku funkcyjnym (wszystkie punkty układają się na linii prostej);
wartość zero świadczy o braku związku, co odpowiada linii poziomej lub pionowej
(por. rysunek <a href="causality.html#fig:correlations5">4.3</a>).</p>
<div class="figure"><span style="display:block;" id="fig:correlations5"></span>
<img src="correlation_expl.png" alt="Wykresy rozrzutu dla korelacji o różnej sile" width="99%" />
<p class="caption">
Rysunek 4.3: Wykresy rozrzutu dla korelacji o różnej sile
</p>
</div>
<p>Interpretacja opisowa: wartości powyżej 0,9 świadczą o silnej zależności.</p>
<div class="example">
<p><span id="exm:unlabeled-div-33" class="example"><strong>4.13  </strong></span><strong>Zamożność a konsumpcja mięsa (kontynuacja)</strong></p>
<p>Współczynnik korelacji liniowej wynosi 0,6823158 (umiarkowana korelacja).</p>
<p>Czy ta wartość jest istotnie różna od zera? Jest na to stosowny
test statystyczny, który sprowadza się do określenia, jakie jest
prawdopodobieństwo otrzymania r = 0,6823158 przy założeniu, że
prawdziwa wartość r wynosi zero. Otóż w naszym przykładzie
to prawdopodobieństwo wynosi 3.850676e-26
(czyli jest ekstremalnie małe – r jest istotnie różne od zera).</p>
</div>
</div>
<div id="macierz-korelacji" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Macierz korelacji<a href="causality.html#macierz-korelacji" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wstępnym etapem analizy zależności między zmiennymi jest często
hurtowa ocena współczynników korelacji w postaci kwadratowej <strong>macierzy korelacji</strong>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-34" class="example"><strong>4.14  </strong></span><strong>Korelacja pomiędzy wiekiem, edukacją, szczęściem a stanem zdrowia</strong></p>
<p>S. Mohammadi i inni badali zależność pomiędzy wiekiem, poziomem edukacji, szczęściem a stanem zdrowia.
(The relationship between happiness and self-rated health: A population-based study of 19499 Iranian adults;
<a href="https://doi.org/10.1371/journal.pone.0265914" class="uri">https://doi.org/10.1371/journal.pone.0265914</a>).</p>
<pre><code>##               age     edu Happiness Health
## age        1,0000 -0,1834    0,0449 0,0013
## edu       -0,1834  1,0000    0,0742 0,0000
## Happiness  0,0449  0,0742    1,0000 0,1786
## Health     0,0013  0,0000    0,1786 1,0000</code></pre>
<p>Albo w bardziej efektownej postaci tekstowo-graficznej:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-54-1.png" width="75%" /></p>
<p>Ze wszystkich zmiennych analizowanych w badaniu Mohammadiego i innych
jedynie zależność pomiędzy wiekiem a wykształceniem
(raczej trywialna) oraz szczęściem i zdrowiem (raczej oczywista) okazały się
znacząco różne od zera.</p>
</div>
</div>
<div id="pomiar-siły-zależności-regresja-liniowa" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Pomiar siły zależności: regresja liniowa<a href="causality.html#pomiar-siły-zależności-regresja-liniowa" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Regresja liniowa</strong> zakłada, że istnieje związek przyczyna-skutek
i ten związek można opisać linią prostą (stąd liniowa). Skutek jest
jeden i nazywa się go <strong>zmienną zależną</strong>, a przyczyn może być wiele i noszą
nazwę <strong>zmiennych niezależnych</strong> (albo <strong>predyktorów</strong>).
W przypadku gdy związek dotyczy dwóch zmiennych mówi się o <strong>regresji prostej</strong>.
Przykładowo zależność
pomiędzy spożywaniem kawy w czasie sesji egzaminacyjnej a wynikiem egzaminu
można formalnie zapisać jako:</p>
<p><span class="math display">\[ \textrm{wynik} = b_0 + b_1 \cdot \textrm{kawa}\]</span></p>
<p>Współczynnik <span class="math inline">\(b_1\)</span> określa wpływ spożycia kawy na wynik egzaminu.
W szczególności jeżeli <span class="math inline">\(b_1 = 0\)</span>, to
nie ma związku między spożywaniem kawy a wynikiem egzaminu.</p>
</div>
<div id="regProsta" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Regresja prosta<a href="causality.html#regProsta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Równanie regresji dla zmiennych <span class="math inline">\(Y\)</span> (skutek) oraz <span class="math inline">\(X\)</span> (przyczyna) można zapisać następująco:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X + e \]</span></p>
<p><span class="math inline">\(Y = b_0 + b_1 \cdot X\)</span> to <strong>część deterministyczna</strong>,
a <span class="math inline">\(e\)</span> oznacza <strong>składnik losowy</strong>.
O tym składniku zakładamy, że średnia jego wartość wynosi zero.
Można to sobie wyobrazić następująco: w populacji jest jakaś prawdziwa zależność
<span class="math inline">\(Y = b_0 + b_1 \cdot X\)</span> pomiędzy <span class="math inline">\(X\)</span> a <span class="math inline">\(Y\)</span>, która w próbie
ujawnia się z błędem o charakterze losowym. Ten błąd może wynikać
z pominięcia pewnej ważnej zmiennej (model
jest zawsze uproszczeniem rzeczywistości), przybliżonego charakteru linii
prostej jako zależności pomiędzy <span class="math inline">\(X\)</span> a <span class="math inline">\(Y\)</span> (prosta, ale nie do końca prosta)
albo błędu pomiaru.</p>
<p>Współczynnik <span class="math inline">\(b_1\)</span> (nachylenia prostej) określa wielkość efektu
w przypadku regresji, tj. siły zależności pomiędzy zmiennymi.</p>
<p>Współczynnik <span class="math inline">\(b_1\)</span> ma prostą interpretację: jeżeli wartość zmiennej <span class="math inline">\(X\)</span>
rośnie o jednostkę to wartość zmiennej <span class="math inline">\(Y\)</span> zmienia
się przeciętnie o <span class="math inline">\(b_1\)</span> jednostek zmiennej Y.
Wyraz wolny zwykle nie ma sensownej interpretacji, formalnie jest to wartość zmiennej <span class="math inline">\(Y\)</span> dla <span class="math inline">\(X=0\)</span>.</p>
<p>Oznaczmy przez <span class="math inline">\(y_i\)</span> wartości obserwowane (zwane też empirycznymi),
a przez <span class="math inline">\(\hat y_i\)</span> <em>wartości teoretyczne</em> (leżące na prostej linii regresji).</p>
<p>Wartości <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span> wyznacza się, minimalizując sumę kwadratów
odchyleń wartości teoretycznych od wartości empirycznych, tj.:</p>
<p><span class="math display">\[(\hat y_1 - y_1)^2 + (\hat y_2 - y_2)^2 + ... +  (\hat y_n - y_n)^2 \to \min\]</span></p>
<p>Rozwiązując powyższy <strong>problem minimalizacyjny</strong>, otrzymujemy wzory
określające wartości parametrów <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span>. Metoda wyznaczania parametrów
linii prostej w oparciu o minimalizację sumy kwadratów odchyleń
nosi nazwę <strong>metody najmniejszych kwadratów</strong>.</p>
<p>Przypominamy, że <strong>estymatorem</strong> nazywamy metodę oszacowania parametru na podstawie próby.
Ponieważ traktujemy <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span> jako parametry pewnej populacji generalnej,
to „wzory na <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span>“ statystyk nazwie estymatorami parametrów <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span>.</p>
<p>Przypominamy też, że wartość średnia <strong>dobrego estymatora</strong> powinna wynosić zero (bo wtedy nie ma błędu systematycznego)
oraz że wariancja estymatora powinna maleć wraz ze wzrostem liczebności próby. Można udowodnić,
że estymatory parametrów <span class="math inline">\(b_0\)</span> oraz <span class="math inline">\(b_1\)</span>
uzyskane <strong>metodą najmniejszych kwadratów</strong> mają obie właściwości.</p>
<p>Graficznie <strong>kryterium minimalizacyjne</strong> przedstawia rysunek <a href="causality.html#fig:KMNK">4.4</a>.</p>
<div class="figure"><span style="display:block;" id="fig:KMNK"></span>
<img src="kmnk_roznice.png" alt="Metoda najmniejszych kwadratów" width="80%" />
<p class="caption">
Rysunek 4.4: Metoda najmniejszych kwadratów
</p>
</div>
<p>Suma podniesionych do kwadratu odległości pomiędzy czerwonymi
(leżącymi na linii prostej w wersji czarno-białej)
i niebieskimi kropkami ma być minimalna. Kropki niebieskie to
wartości empiryczne; kropki czerwone to wartości teoretyczne.
Zadanie wyznaczenie
parametrów takiej prostej oczywiście realizuje program komputerowy.</p>
<p>Można udowodnić, że bez względu na to, czy punkty na wykresie układają się
w przybliżeniu wzdłuż prostej, czy nie, zawsze <strong>jakaś prosta</strong> zostanie
dopasowana (jeżeli tylko punktów jest więcej niż jeden).
Jak ocenić w sposób bardziej konkretny, a nie tylko na oko jakość dopasowania
prostej do wartości empirycznych?</p>
<p><strong>Ocena dopasowania: wariancja resztowa oraz średni błąd szacunku</strong></p>
<p>Oznaczając <em>resztę</em> jako: <span class="math inline">\(e_i = y_i - \hat y_i\)</span>, definiujemy <strong>wariancję
resztową</strong> jako:</p>
<p><span class="math display">\[s_e^2 = \frac{e_1^2 + e_2^2 + ... + e_n^2}{n-k}\]</span>.</p>
<p>Gdzie <span class="math inline">\(n\)</span> oznacza liczbę obserwacji (liczebność próby), a <span class="math inline">\(k\)</span> liczbę
szacowanych parametrów bez wyrazu wolnego czyli jeden w regresji
prostej (a więcej niż jeden w regresji wielorakiej, o czym dalej).</p>
<p>Pierwiastek kwadratowy z <strong>wariancji resztowej</strong>
nazywamy <strong>średnim błędem szacunku</strong> (<em>mean square error</em>, MSE).</p>
<p><strong>Ocena dopasowania: współczynniki zbieżności i determinacji</strong></p>
<p>Suma kwadratów reszt (albo odchyleń wartości teoretycznych
od wartości empirycznych,
albo suma kwadratów błędów vel <strong>resztowa suma kwadratów</strong>):</p>
<p><span class="math display">\[\mathrm{RSK} = (y_1 - \hat y_1)^2 + (y_2 - \hat y_2)^2 + ... +  (y_n - \hat y_n)^2\]</span>.</p>
<p>Suma kwadratów odchyleń wartości empirycznych od średniej (ogólna suma kwadratów):</p>
<p><span class="math display">\[\mathrm{OSK} = (y_1 - \bar y)^2 + (y_2 - \bar y)^2 + ... +  (y_n - \bar y)^2\]</span></p>
<p>Suma kwadratów odchyleń wartości teoretycznych od średniej (wyjaśniona suma kwadratów):</p>
<p><span class="math display">\[\mathrm{WSK} = (\hat y_1 - \bar y)^2 + (\hat y_2 - \bar y)^2 + ... +  (\hat y_n - \bar y)^2\]</span></p>
<p>Można wykazać, że <span class="math inline">\(\mathrm{OSK} = \mathrm{WSK} + \mathrm{RSK}\)</span> zatem (po podzieleniu obu stron
równania przez <span class="math inline">\(\mathrm{OSK}\)</span>) otrzymujemy:</p>
<p><span class="math display">\[ 1 =  \mathrm{WSK}/\mathrm{OSK} + \mathrm{RSK}/\mathrm{OSK}\]</span></p>
<p><strong>Współczynnik zbieżności</strong> oznaczany jako <span class="math inline">\(R^2\)</span> to <span class="math inline">\(\mathrm{WSK}/\mathrm{OSK}\)</span>.</p>
<p><strong>Współczynnik determinacji</strong> oznaczany jako <span class="math inline">\(\Phi^2\)</span> (duża grecka litera Fi) to <span class="math inline">\(\mathrm{RSK}/\mathrm{OSK}\)</span>.</p>
<p>Współczynniki przyjmują wartość z przedziału <span class="math inline">\([0,1]\)</span> lub <span class="math inline">\([0, 100]\)</span>%, jeżeli
ich wartości zostaną pomnożone przez 100.</p>
<p>Interpretacja współczynnika zbieżności: udział (procent) zmienności wyjaśnianej
przez linię regresji. Im <span class="math inline">\(R^2\)</span> jest bliższe jedności (lub 100% jeżeli
współczynnik zbieżności jest wyrażony w procentach), tym lepiej.</p>
<p><strong>Ocena dopasowania: istotność parametru <span class="math inline">\(b_1\)</span></strong></p>
<p>Jeżeli: <span class="math inline">\(Y= 0 \cdot X + b_0\)</span>, to <span class="math inline">\(Y = b_0\)</span>, czyli nie ma zależności
pomiędzy <span class="math inline">\(X\)</span> oraz <span class="math inline">\(Y\)</span>.
Wartości <span class="math inline">\(b_1\)</span> bliskie zero wskazują na słabą zależność
pomiędzy cechami.</p>
<p>Przypominamy, że <strong>estymator</strong> parametru <span class="math inline">\(b_1\)</span> ma średnią równą prawdziwej wartości <span class="math inline">\(b_1\)</span>.
Dodatkowo zakładamy, że rozkład tego estymatora jest normalny, co
pozwala wiarygodnie oszacować jego wariancję.
W konsekwencji znamy jego dokładny rozkład, bo przypominamy, że rozkład
normalny jest określony przez dwa parametry: średnią oraz wariancję (lub
odchylenie standardowe).</p>
<p>Można teraz zadać pytanie: jeżeli faktycznie <span class="math inline">\(b_1=0\)</span>, to jakie jest prawdopodobieństwo, że
współczynnik <span class="math inline">\(b_1\)</span> oszacowany
na podstawie <span class="math inline">\(n\)</span> obserwacji będzie (co do wartości bezwzględnej) większy niż <span class="math inline">\(b_e\)</span>?
Albo inaczej: otrzymaliśmy <span class="math inline">\(b_e\)</span>, jakie jest prawdopodobieństwo
otrzymania takiej wartości (lub większej co do wartości bezwzględnej)
przy założeniu, że istotnie <span class="math inline">\(b_1=0\)</span>?</p>
<p>Jeżeli takie prawdopodobieństwo jest duże, to uznajemy, że <span class="math inline">\(b_1 = 0\)</span>,
a jeżeli małe, to będziemy raczej sądzić, że <span class="math inline">\(b_1 \not= 0\)</span>.
Duże/małe przyjmujemy arbitralnie, zwykle
jest to <span class="math inline">\(0,1\)</span>, <span class="math inline">\(0,05\)</span> lub <span class="math inline">\(0,01\)</span>. To prawdopodobieństwo
to oczywiście poziom istotności.</p>
<p>W każdym programie komputerowym na wydruku wyników linii regresji są podane wartości
prawdopodobieństwa <span class="math inline">\(b_1 &gt; b_e\)</span> (co do wartości bezwzględnej). Jeżeli jest
ono mniejsze
niż ustalony <strong>poziom istotności</strong>, to <span class="math inline">\(b_1\)</span> ma wartość istotnie różną od zera.
Oprócz wartości prawdopodobieństwa drukowana jest także wartość
błędu standardowego parametru zwykle oznaczana jako <code>SE</code> (<em>standard error</em>). Wartość
<code>SE</code> nie jest wprawdzie potrzebna do oceny istotności (wystarczy prawdopodobieństwo), ale
dobry zwyczaj nakazuje podawać także tę wartość w raporcie.</p>
<p>Testowanie istotności współczynnika regresji jest ważnym kryterium oceny
jakości dopasowania.
Regresja z <strong>nieistotnym</strong> współczynnikiem nie
może być podstawą do interpretowania zależności pomiędzy <span class="math inline">\(X\)</span> oraz <span class="math inline">\(Y\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-35" class="example"><strong>4.15  </strong></span><strong>Waga a wzrost rugbystów</strong></p>
<p>Zależność między wagą (<code>weight</code>) a wzrostem (<code>height</code>):</p>
<p><span class="math display">\[ \textrm{height} = b_0 + b_1 \textrm{weight}\]</span>
Oszacowanie tego równania na próbie 635 uczestników
Pucharu Świata w rugby w 2023 roku
daje następujące wyniki:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">155,926</td>
<td align="right">1,753</td>
<td align="right">88,969</td>
<td align="right">0</td>
<td align="left">152,48 159,37</td>
</tr>
<tr class="even">
<td align="left">weight</td>
<td align="right">0,294</td>
<td align="right">0,017</td>
<td align="right">17,305</td>
<td align="right">0</td>
<td align="left">0,26 0,33</td>
</tr>
</tbody>
</table>
<p>Kolumna <code>Zmienna</code> zawiera nazwy zmiennych (<code>(Intercept)</code> oznacza wyraz wolny).
Druga kolumna oznaczona jako <code>B</code> zawiera oszacowane wartości (oceny) parametrów linii regresji.
Kolumna <code>SE</code> zawiera oceny błędu standardowego estymatorów parametrów linii regresji.
Kolumna <code>p</code> zawiera prawdopodobieństwo <span class="math inline">\(b&gt;b_e\)</span>.</p>
<p>Wzrost wagi zawodnika o 1 kg
skutkuje przeciętnie większym wzrostem o 0,294 cm. Współczynnik determinacji
wynosi 32,86%.
Współczynnik nachylenia prostej jest istotny, ponieważ wartość <span class="math inline">\(p\)</span> (tak mała, że w tabeli
oznaczona jako 0)
jest grubo poniżej zwyczajowego poziomu istotności (p &lt; 0,05).</p>
<p>Kolumna <code>CI95</code> zawiera 95% przedziały ufności: z 95-proc. prawdopodobieństwem wartość współczynnika nachylenia
prostej znajduje się w przedziale 0.260–0.330.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-57-1.png" width="75%" /></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-36" class="example"><strong>4.16  </strong></span><strong>Zamożność a konsumpcja mięsa</strong></p>
<p>Poniższe równanie opisuje zależność pomiędzy dochodem narodowym na głowę (tys. USD <em>per capita</em>)
a konsumpcją mięsa w kilogramach:</p>
<p><span class="math display">\[\textrm{konsumpcja} = b_0 + b_1 \textrm{gdp}\]</span></p>
<p>Model oszacowano dla krajów świata w roku 2013 na podstawie danych
pobranych z bazy FAO Food Balance Sheet oraz Banku Światowego, otrzymując
następujące wyniki:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-59-1.png" width="75%" /></p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">34,085</td>
<td align="right">2,232</td>
<td align="right">15,268</td>
<td align="right">0</td>
<td align="left">29,7 38,5</td>
</tr>
<tr class="even">
<td align="left">gdp2013</td>
<td align="right">0,001</td>
<td align="right">0,000</td>
<td align="right">11,124</td>
<td align="right">0</td>
<td align="left">0,0 0,0</td>
</tr>
</tbody>
</table>
<p>Każdy 1000 USD <em>per capita</em> więcej dochodu narodowego (GDP) oznacza przeciętny
wzrost spożycia mięsa o 0,001 kg. Przeciętna różnica wartości teoretycznych
od empirycznych wynosi 21,04 kg (średni błąd szacunku).
Współczynnik zbieżności wynosi 40,88%.
Współczynnik nachylenia prostej (którego wartość
wynosi 0,001) jest statystycznie istotny.</p>
</div>
<p>Nie ma przykładów zastosowania regresji prostej w literaturze przedmiotu,
bo jest ona zbyt dużym uproszczeniem rzeczywistości. Jest to jednak
dobry punkt startu do bardziej skomplikowanego modelu <strong>regresji wielorakiej</strong>.</p>
</div>
</div>
<div id="zmienna-liczbowa-i-zmienne-liczbowe-lub-nominalne" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Zmienna liczbowa i zmienne liczbowe lub nominalne<a href="causality.html#zmienna-liczbowa-i-zmienne-liczbowe-lub-nominalne" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="regresja-wieloraka" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Regresja wieloraka<a href="causality.html#regresja-wieloraka" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jeżeli zmiennych niezależnych jest więcej niż jedna,
to mówimy o <strong>regresji wielorakiej</strong>. Przykładowo
zależność
pomiędzy wynikiem egzaminu, spożyciem kawy czasem nauki oraz predyspozycjami
opisuje następujący model regresji:</p>
<p><span class="math display">\[\textrm{wynik} = b_0 + b_1 \cdot \textrm{kawa} + b_2 \cdot \textrm{czas} + b_3 \cdot \textrm{predyspozycje} \]</span></p>
<p>Współczynnik <span class="math inline">\(b_1\)</span> określa wpływ spożycia kawy,
<span class="math inline">\(b_2\)</span> czasu poświęconego na naukę,
a <span class="math inline">\(b_3\)</span> predyspozycji
(intelektualnych, mierzonych np. średnią ocenę ze studiów). Ogólnie
model
regresji wielorakiej zapisać można jako:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2 + ... + b_k \cdot X_k \]</span></p>
<p>Wpływ każdej
zmiennej <span class="math inline">\(X_i\)</span> na zmienną zależną <span class="math inline">\(Y\)</span> jest określony przez odpowiedni współczynnik <span class="math inline">\(b_i\)</span>.
Zmienne <span class="math inline">\(X_i\)</span> mogą być zmiennymi liczbowymi lub nominalnymi.</p>
<p>Podobnie jak w przypadku regresji prostej do oceny stopnia dopasowania modelu do danych
wykorzystuje się: średni błąd szacunku, współczynnik zbieżności <span class="math inline">\(R^2\)</span> oraz
weryfikuje się istotność współczynników <span class="math inline">\(b_i\)</span>.</p>
<p><strong>Standaryzacja współczynników regresji</strong></p>
<p>Ponieważ współczynniki regresji <span class="math inline">\(b_1, …, b_k\)</span> mogą być wyrażone w różnych jednostkach miary,
bezpośrednie ich porównanie jest niemożliwe; mały współczynnik może w rzeczywistości być ważniejszy niż większy.
Jeżeli chcemy porównywać wielkości współczynników, to trzeba je <strong>zestandaryzować</strong>.</p>
<p>Standaryzowany współczynnik regresji dla <span class="math inline">\(i\)</span>-tej zmiennej
obliczony jest poprzez pomnożenie współczynnika regresji <span class="math inline">\(b_i\)</span> przez <span class="math inline">\(s_{xi}\)</span>
i podzielenie przez <span class="math inline">\(s_y\)</span>:</p>
<p><span class="math display">\[\beta_i = b_i \frac{s_{xi}}{s_y}\]</span></p>
<p>Dla przypomnienia: <span class="math inline">\(s_{xi}\)</span>
to odchylenie standardowe zmiennej <span class="math inline">\(X_i\)</span>, a <span class="math inline">\(s_y\)</span> to odchylenie standardowe zmiennej <span class="math inline">\(Y\)</span>.
Interpretacja współczynnika standaryzowanego jest cokolwiek dziwaczna:
zmiana zmiennej <span class="math inline">\(X_i\)</span> o jedno odchylenie standardowe (<span class="math inline">\(s_{xi}\)</span>)
skutkuje zmianą zmiennej <span class="math inline">\(Y\)</span> o <span class="math inline">\(b_i\)</span> jej odchylenia standardowego <span class="math inline">\(s_y\)</span>.
Na szczęście współczynniki regresji standaryzuje się nie w celu lepszej interpretacji,
tylko w celu umożliwienia porównania ich względnej wielkości (<em>wielkości efektu</em>).
W publikacjach medycznych zwykle używa się litery <span class="math inline">\(b\)</span> na
oznaczenie współczynników niestandaryzowanych,
a litery <span class="math inline">\(\beta\)</span> na oznaczenie współczynników standaryzowanych.</p>
<p><strong>Wielkość efektu</strong></p>
<p>Współczynniki regresji to miara wielkości efektu, która wskazuje na siłę zależności między zmiennymi.
Standaryzacja pozwala na porównanie wielkości efektu zmiennych mierzonych w różnych jednostkach miary.
Standaryzacja przydaje się także w przypadku posługiwania się skalami pomiarowymi mierzącymi
przekonania i postawy, które z definicji są bezjednostkowe.</p>
<p><strong>Wybór zmiennych objaśniających</strong></p>
<p>Zwykle jest tak, że do objaśniania kształtowania się wartości zmiennej <span class="math inline">\(Y\)</span> kandyduje wiele potencjalnych
predyktorów <span class="math inline">\(X_k\)</span>.
Model zawierający wszystkie <span class="math inline">\(X_k\)</span> predyktory niekoniecznie będzie najlepszy.
Nie wdając się w omawianie szczegółowych zasad, poprzestaniemy na dwóch kryteriach:</p>
<ol style="list-style-type: decimal">
<li><p>Model prostszy jest lepszy od modelu bardziej skomplikowanego, jeżeli adekwatnie objaśnia zmienność <span class="math inline">\(Y\)</span>
(zasada brzytwy Ockhama).</p></li>
<li><p>Model powinien zawierać tylko zmienne o współczynnikach, których wartości są statystycznie różne od zera.</p></li>
</ol>
<p>Regresja krokowa (<em>stepwise regression</em>) jest metodą wyboru najlepszych predyktorów
spośród większego zbioru zmiennych. Występuje w dwóch wariantach: <strong>dołączania</strong> i <strong>eliminacji</strong>.
Ponieważ <strong>eliminacja</strong> wydaje się prostsza, omówimy tylko ten wariant.</p>
<p>W metodzie eliminacji początkowym modelem jest model zawierający wszystkie potencjalne <span class="math inline">\(X_k\)</span> predyktory.
Następnie testujemy istotność wszystkich współczynników regresji i usuwamy
ze zbioru predyktorów ten, który jest „najbardziej nieistotny“ (ma największą wartość <span class="math inline">\(p\)</span>).
Procedurę powtarzamy dla modelu bez usuniętej zmiennej.
Procedurę przerywamy, gdy wszystkie współczynniki regresji są statystycznie istotne.</p>
<div class="example">
<p><span id="exm:unlabeled-div-37" class="example"><strong>4.17  </strong></span><strong>Zależność pomiędzy ciśnieniem skurczowym, BMI oraz wiekiem</strong></p>
<p><span class="math display">\[\textrm{ciśnienie} = b_0 + b_1 \textrm{BMI} + b_2\textrm{wiek}\]</span></p>
<p>Dane pochodzą z badania: Zależność pomiędzy BMI i wiekiem a występowaniem cukrzycy
wśród dorosłych osób w Chinach. Badanie kohortowe (Chen i inni, <em>Association of body mass index
and age with incident diabetes in Chinese adults: a population-based cohort study.</em>
BMJ Open. 2018 Sep 28;8(9):e021768. doi: 10.1136/bmjopen-2018-021768. PMID: 30269064; PMCID: PMC6169758).</p>
<p>Oryginalny zbiór danych liczy 60 tysięcy obserwacji. Dla celów przykładu losowo wybrano 90, 490
oraz 4490 obserwacji. Zobaczymy, jaki ma wpływ wielkość próby na wynik szacowania modelu.</p>
<p>Oszacowanie równania dla próby o wielkości 90 obserwacji daje następujące wyniki:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">59,698</td>
<td align="right">11,965</td>
<td align="right">4,990</td>
<td align="right">0,000</td>
<td align="right">NA</td>
<td align="left">35,92 83,48</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,742</td>
<td align="right">0,486</td>
<td align="right">3,583</td>
<td align="right">0,001</td>
<td align="right">0,33</td>
<td align="left">0,78 2,71</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,484</td>
<td align="right">0,124</td>
<td align="right">3,906</td>
<td align="right">0,000</td>
<td align="right">0,36</td>
<td align="left">0,24 0,73</td>
</tr>
</tbody>
</table>
<p>Współczynnik zbieżności wynosi 26,24%.
Kolumna <code>Beta</code> zawiera standaryzowane
oceny parametrów regresji. Tej kolumny na poprzednich wydrukach
(punkt <a href="causality.html#regProsta">4.3.5</a>)
nie było, bo w przypadku regresji
prostej standaryzacja jest zabiegiem raczej zbędnym. Dla wyrazu wolnego
nie ma wartości standaryzowanej (co oznaczono jako <code>NA</code>, czyli <em>not available</em>),
ale to żadna strata – oceny tego parametru nie są interpretowane.
Wpływ <code>BMI</code> na wielkość ciśnienia jest nieco niższy niż <code>age</code>.</p>
<p>Oszacowanie równania dla próby o wielkości 490 obserwacji daje następujące
wyniki:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">79,061</td>
<td align="right">4,378</td>
<td align="right">18,057</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="left">70,46 87,66</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,213</td>
<td align="right">0,183</td>
<td align="right">6,637</td>
<td align="right">0</td>
<td align="right">0,28</td>
<td align="left">0,85 1,57</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,259</td>
<td align="right">0,053</td>
<td align="right">4,856</td>
<td align="right">0</td>
<td align="right">0,21</td>
<td align="left">0,15 0,36</td>
</tr>
</tbody>
</table>
<p>Współczynnik zbieżności wynosi 14,97%.
Wpływ <code>BMI</code> na wielkość ciśnienia jest teraz wyższy niż <code>age</code>. Przedziały ufności są węższe,
co wynika z większej liczebności próby.</p>
<p>Oszacowanie równania dla próby o wielkości 4490 obserwacji daje następujące
wyniki:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">74,011</td>
<td align="right">1,530</td>
<td align="right">48,358</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="left">71,01 77,01</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,375</td>
<td align="right">0,064</td>
<td align="right">21,404</td>
<td align="right">0</td>
<td align="right">0,30</td>
<td align="left">1,25 1,50</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,320</td>
<td align="right">0,018</td>
<td align="right">18,270</td>
<td align="right">0</td>
<td align="right">0,25</td>
<td align="left">0,29 0,35</td>
</tr>
</tbody>
</table>
<p>Współczynnik zbieżności wynosi 18,54%.
Przedziały ufności są jeszcze węższe. Ocena <code>age</code>
z 95-proc. prawdopodobieństwem znajduje się w przedziale [0,290 0,350]
a w pierwszym oszacowaniu dla znacznie mniejszej próby było to [0,240 0,730].
Przedział jest ponad 8 razy węższy.</p>
</div>
</div>
<div id="zmienne-zero-jedynkowe" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Zmienne zero-jedynkowe<a href="causality.html#zmienne-zero-jedynkowe" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Zamiast (celem wykazania związku między zmienną liczbową a nominalną) porównywać
średnie w grupach możemy wykorzystać metodę regresji
wielorakiej. Zmienna nominalna jest zamieniana na jedną lub więcej
zmiennych binarnych, które przyjmują tylko dwie wartości 0 lub 1.</p>
<p>Przykładowo rodzaj miejsca pracy (skala nominalna; dwie wartości: szpital, przychodnia)
można zamienić na zmienną binarną <code>praca</code>, przypisując 1 = szpital, oraz
0 = przychodnia (lub odwrotnie). Załóżmy, że poziom stresu zależy od stażu pracy, satysfakcji
(obie mierzone na skali liczbowej)
i rodzaju miejsca pracy. Możemy to zapisać jako następujące równanie regresji:</p>
<p><span class="math display">\[\textrm{stres} = b_0 + b_1\cdot \textrm{staż} + b_2 \cdot \textrm{satysfakcja} + b_3\cdot \textrm{praca}\]</span></p>
<p>Jaka jest interpretacja współczynnika <span class="math inline">\(b_3\)</span>? Zakładając że 0 = przychodnia, <span class="math inline">\(b_3\)</span> oznacza
przeciętną zmianę wielkości stresu
spowodowaną pracą w szpitalu w porównaniu do pracy w przychodni. Jeżeli ten współczynnik jest istotny
statystycznie, to istnieje zależność pomiędzy stresem a miejscem pracy. Czyli zamiast
stosować test <span class="math inline">\(t\)</span> Welcha i porównywać średnie w grupach,
możemy oszacować model regresji z wykorzystaniem stosownej
zmiennej zero-jedynkowej, a następnie sprawdzić, czy współczynnik stojący przy tej zmiennej jest istotny.</p>
<p>Jeżeli zmienna nominalna ma <span class="math inline">\(n\)</span> wartości, należy ją zamienić na <span class="math inline">\(n-1\)</span> zmiennych zero-jedynkowych.
Załóżmy że stres zależy także od wykształcenia, mierzonego w skali nominalnej
(średnie, licencjat, magisterskie). Tworzymy dwie zmienne:
magister (1, jeżeli respondent ma wykształcenie magisterskie, lub 0, jeżeli nie ma)
oraz licencjat (1, jeżeli respondent ma licencjat, lub 0, jeżeli nie ma). Równanie
regresji ma postać:</p>
<p><span class="math display">\[\textrm{stres} = b_0 + b_1\textrm{staż} + b_2 \textrm{satysfakcja} + b_3 \textrm{praca}
+ b_4 \textrm{magister} + b_5 \textrm{licencjat} \]</span></p>
<p>Jeżeli <span class="math inline">\(\textrm{magister} = 0\)</span> oraz <span class="math inline">\(\textrm{licencjat} = 0\)</span>, to osoba ma wykształcenie średnie.</p>
<p>Interpretacja: <span class="math inline">\(b_4\)</span> (jeżeli istotne) oznacza przeciętną zmianę wielkości stresu osoby z wykształceniem magisterskim w porównaniu do osoby z wykształceniem średnim. Podobnie <span class="math inline">\(b_5\)</span> oznacza przeciętną zmianę
wielkości stresu osoby z wykształceniem licencjackim
w porównaniu do osoby z wykształceniem średnim.</p>
<div class="example">
<p><span id="exm:unlabeled-div-38" class="example"><strong>4.18  </strong></span><strong>Zależność pomiędzy ciśnieniem skurczowym, BMI, wiekiem, płcią, paleniem i piciem</strong></p>
<p>Poprzednio rozważany model
rozszerzymy o trzy zmienne: płeć (kobieta/mężczyzna),
status względem picia alkoholu (pije, pił, nigdy nie pił)
oraz status względem palenia (palił, pali, nigdy nie palił).
Zwróćmy uwagę, że zmienne mierzące status względem palenia/picia mają nie dwie, a trzy wartości.
Należy każdą zamienić na dwie zmienne binarne, według schematu:</p>
<p><code>CS</code> (pali) = 1 jeżeli pali, 0 w przeciwnym przypadku;</p>
<p><code>PS</code> (palił) = 1 jeżeli palił, ale nie pali, 0 w przeciwnym przypadku;</p>
<p><code>CD</code> (pije) oraz <code>PD</code> (pił) <em>per analogiam</em> do <code>CS</code>/<code>CD</code>.</p>
<p>Zmienna płeć <code>genderF</code> = 1, jeżeli kobieta, lub 0, jeżeli mężczyzna. Zauważmy, że nazwa zmiennej
dwuwartościowej wskazuje, która wartość jest zakodowana jako 1. Przykładowo <code>genderF</code> (<em>female</em>, żeby się
trzymać języka angielskiego) wskazuje, że jedynką jest kobieta.
Taka konwencja ułatwia interpretację. Gdybyśmy zamiast <code>genderF</code> nazwali zmienną <code>gender</code>, to na pierwszy
rzut oka nie byłoby wiadomo, co zakodowano jako jeden. A tak wiadomo od razu, jak
interpretować parametr stojący przy tej zmiennej: zmiana wielkości ciśnienia u kobiet w porównaniu do mężczyzn.</p>
<p>Rozważany model ma postać:</p>
<p><span class="math display">\[\begin{align}
SBP &amp;= b_0 + b_1 \textrm{BMI} + b_2 \textrm{age} + b_3 \textrm{genderF} + b_4 \textrm{CS} +\nonumber\\
&amp;+  b_5 \textrm{PS} + b_6 \textrm{CD} + b_7 \textrm{PD} \nonumber
\end{align}\]</span></p>
<p>Oszacowanie dla próby o wielkości 90 obserwacji daje następujące wyniki:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">90,332</td>
<td align="right">15,745</td>
<td align="right">5,737</td>
<td align="right">0,000</td>
<td align="right">NA</td>
<td align="left">59,01 121,65</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">0,778</td>
<td align="right">0,592</td>
<td align="right">1,314</td>
<td align="right">0,193</td>
<td align="right">0,15</td>
<td align="left">-0,40 1,96</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,441</td>
<td align="right">0,121</td>
<td align="right">3,658</td>
<td align="right">0,000</td>
<td align="right">0,33</td>
<td align="left">0,20 0,68</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">-13,820</td>
<td align="right">4,399</td>
<td align="right">-3,141</td>
<td align="right">0,002</td>
<td align="right">-0,40</td>
<td align="left">-22,57 -5,07</td>
</tr>
<tr class="odd">
<td align="left">CS</td>
<td align="right">-6,890</td>
<td align="right">3,972</td>
<td align="right">-1,735</td>
<td align="right">0,087</td>
<td align="right">-0,18</td>
<td align="left">-14,79 1,01</td>
</tr>
<tr class="even">
<td align="left">PS</td>
<td align="right">7,626</td>
<td align="right">6,882</td>
<td align="right">1,108</td>
<td align="right">0,271</td>
<td align="right">0,11</td>
<td align="left">-6,07 21,32</td>
</tr>
<tr class="odd">
<td align="left">CD</td>
<td align="right">-3,959</td>
<td align="right">8,523</td>
<td align="right">-0,465</td>
<td align="right">0,643</td>
<td align="right">-0,04</td>
<td align="left">-20,91 13,00</td>
</tr>
<tr class="even">
<td align="left">PD</td>
<td align="right">-4,001</td>
<td align="right">4,575</td>
<td align="right">-0,875</td>
<td align="right">0,384</td>
<td align="right">-0,08</td>
<td align="left">-13,10 5,10</td>
</tr>
</tbody>
</table>
<p>Współczynnik zbieżności wynosi 38,11%. Tylko dwie na siedem zmiennych
są istotne. Zwróćmy uwagę, że nieistotnie zmienne mają przedziały ufności zawierające zero. W konsekwencji
z 95-proc. prawdopodobieństwem wartości tych współczynników mogą być raz ujemne, raz dodatnie – nie mamy
nawet pewności co do kierunku zależności między zmienną objaśniającą a ciśnieniem.
Zmienne, które okazały się istotne, jednocześnie mają największą wielkość efektu (kolumna <code>Beta</code>)
i nie jest to przypadek.</p>
<p>Wyniki oszacowania równania dla próby o wielkości 4490 obserwacji:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">80,089</td>
<td align="right">1,623</td>
<td align="right">49,334</td>
<td align="right">0,000</td>
<td align="right">NA</td>
<td align="left">76,91 83,27</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,192</td>
<td align="right">0,066</td>
<td align="right">18,009</td>
<td align="right">0,000</td>
<td align="right">0,26</td>
<td align="left">1,06 1,32</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,336</td>
<td align="right">0,018</td>
<td align="right">19,087</td>
<td align="right">0,000</td>
<td align="right">0,26</td>
<td align="left">0,30 0,37</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">-5,329</td>
<td align="right">0,508</td>
<td align="right">-10,496</td>
<td align="right">0,000</td>
<td align="right">-0,16</td>
<td align="left">-6,32 -4,33</td>
</tr>
<tr class="odd">
<td align="left">CS</td>
<td align="right">-2,752</td>
<td align="right">0,583</td>
<td align="right">-4,717</td>
<td align="right">0,000</td>
<td align="right">-0,07</td>
<td align="left">-3,90 -1,61</td>
</tr>
<tr class="even">
<td align="left">PS</td>
<td align="right">-2,021</td>
<td align="right">1,045</td>
<td align="right">-1,933</td>
<td align="right">0,053</td>
<td align="right">-0,03</td>
<td align="left">-4,07 0,03</td>
</tr>
<tr class="odd">
<td align="left">CD</td>
<td align="right">3,621</td>
<td align="right">1,535</td>
<td align="right">2,360</td>
<td align="right">0,018</td>
<td align="right">0,03</td>
<td align="left">0,61 6,63</td>
</tr>
<tr class="even">
<td align="left">PD</td>
<td align="right">0,193</td>
<td align="right">0,623</td>
<td align="right">0,310</td>
<td align="right">0,757</td>
<td align="right">0,00</td>
<td align="left">-1,03 1,41</td>
</tr>
</tbody>
</table>
<p>Współczynnik zbieżności wynosi 20,72%. Zwiększenie
liczebności próby z 90 do 4490 obserwacji spowodowało, że tylko dwie z siedmiu zmiennych
mają nieistotne wartości. Analizując wartości standaryzowane, możemy ustalić,
które zmienne mają największy wpływ na wielkość ciśnienia krwi.</p>
</div>
<p>Ktoś mógłby dojść do wniosku, że wszystko da się „uistotnić”,
wystarczy zwiększyć wielkość próby. Teoretycznie tak, praktycznie nie.
W praktyce nie interesuje nas niewielka wielkość
efektu, czyli znikomy wpływ czegoś na coś. Dodatkowo zebranie dużej próby może
być kosztowne lub wręcz w praktyce niemożliwe – nie mamy dość dużo pieniędzy.
Można teoretycznie określić, jaka wielkość próby pozwoli na ocenę jakiej
wielkości efektu. Sposób postępowania jest wtedy następujący: określamy,
jaka wielkość efektu ma <strong>znaczenie praktyczne</strong>, i na tej podstawie określamy
liczebność próby. Takie zaawansowane podejście
wykracza poza ramy tego podręcznika.</p>
<div class="example">
<p><span id="exm:unlabeled-div-39" class="example"><strong>4.19  </strong></span><strong>Regresja krokowa</strong></p>
<p>W modelu zależność pomiędzy ciśnienie skurczowym, BMI, wiekiem, płcią, paleniem i piciem
(próba 4490) zmienne <code>PD</code> oraz <code>PS</code> są nieistotne, przy czym współczynnik
przy zmiennej <code>PD</code> ma wartość <span class="math inline">\(p\)</span> równą 0,309 zaś przy zmiennej
<code>PS</code> ma wartość 0,05324. Usuwamy zmienną <code>PD</code> (bo wartość <span class="math inline">\(p\)</span> jest większa)
i szacujemy równanie regresji dla sześciu pozostałych zmiennych. Otrzymujemy:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">80,108</td>
<td align="right">1,622</td>
<td align="right">49,387</td>
<td align="right">0,000</td>
<td align="right">NA</td>
<td align="left">76,93 83,29</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,193</td>
<td align="right">0,066</td>
<td align="right">18,056</td>
<td align="right">0,000</td>
<td align="right">0,26</td>
<td align="left">1,06 1,32</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,335</td>
<td align="right">0,018</td>
<td align="right">19,097</td>
<td align="right">0,000</td>
<td align="right">0,26</td>
<td align="left">0,30 0,37</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">-5,358</td>
<td align="right">0,499</td>
<td align="right">-10,740</td>
<td align="right">0,000</td>
<td align="right">-0,16</td>
<td align="left">-6,34 -4,38</td>
</tr>
<tr class="odd">
<td align="left">CS</td>
<td align="right">-2,740</td>
<td align="right">0,582</td>
<td align="right">-4,708</td>
<td align="right">0,000</td>
<td align="right">-0,07</td>
<td align="left">-3,88 -1,60</td>
</tr>
<tr class="even">
<td align="left">PS</td>
<td align="right">-1,980</td>
<td align="right">1,037</td>
<td align="right">-1,910</td>
<td align="right">0,056</td>
<td align="right">-0,03</td>
<td align="left">-4,01 0,05</td>
</tr>
<tr class="odd">
<td align="left">CD</td>
<td align="right">3,579</td>
<td align="right">1,528</td>
<td align="right">2,342</td>
<td align="right">0,019</td>
<td align="right">0,03</td>
<td align="left">0,58 6,58</td>
</tr>
</tbody>
</table>
<p>Współczynnik przy zmiennej <code>PS</code> dalej uparcie jest nieistotny. Usuwamy
teraz tę zmienną. Otrzymujemy:</p>
<table>
<thead>
<tr class="header">
<th align="left">Zmienna</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">Beta</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">79,865</td>
<td align="right">1,618</td>
<td align="right">49,375</td>
<td align="right">0,00</td>
<td align="right">NA</td>
<td align="left">76,69 83,04</td>
</tr>
<tr class="even">
<td align="left">BMI</td>
<td align="right">1,195</td>
<td align="right">0,066</td>
<td align="right">18,075</td>
<td align="right">0,00</td>
<td align="right">0,26</td>
<td align="left">1,07 1,32</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,336</td>
<td align="right">0,018</td>
<td align="right">19,100</td>
<td align="right">0,00</td>
<td align="right">0,26</td>
<td align="left">0,30 0,37</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">-5,155</td>
<td align="right">0,488</td>
<td align="right">-10,572</td>
<td align="right">0,00</td>
<td align="right">-0,16</td>
<td align="left">-6,11 -4,20</td>
</tr>
<tr class="odd">
<td align="left">CS</td>
<td align="right">-2,540</td>
<td align="right">0,573</td>
<td align="right">-4,435</td>
<td align="right">0,00</td>
<td align="right">-0,06</td>
<td align="left">-3,66 -1,42</td>
</tr>
<tr class="even">
<td align="left">CD</td>
<td align="right">3,551</td>
<td align="right">1,529</td>
<td align="right">2,323</td>
<td align="right">0,02</td>
<td align="right">0,03</td>
<td align="left">0,55 6,55</td>
</tr>
</tbody>
</table>
<p>Wszystkie współczynniki mają istotnie różnie od zera wartości. Wartość
współczynnika zbieżności ostatecznego modelu wynosi 20,66%.
Usuwając nieistotne zmienne z modelu, obniżyliśmy wartość
współczynnika zmienności o
20,72% - 20,66% = 0,07%, czyli
tyle, co nic.</p>
</div>
</div>
</div>
<div id="przypadek-specjalny-regresja-logistyczna" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Przypadek specjalny: regresja logistyczna<a href="causality.html#przypadek-specjalny-regresja-logistyczna" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Jeżeli zmienna <span class="math inline">\(Y\)</span> jest zmienną <strong>dwuwartościową</strong>, czyli taką, która przyjmuje tylko dwie
wartości (np. chory/zdrowy), to metoda regresji nie może być zastosowana.
Przykładowo jeżeli zakodujemy te wartości jako chory=0 i zdrowy=1,
to zastosowanie regresji
doprowadzi do obliczenia (teoretycznych) wartości <span class="math inline">\(Y\)</span> różnych od <span class="math inline">\(0\)</span> i <span class="math inline">\(1\)</span>.
Taki wynik nie ma sensownej interpretacji.</p>
<p>Ale zamiast szacować regresję <span class="math inline">\(Y\)</span> względem <span class="math inline">\(X\)</span> (lub <span class="math inline">\(X\)</span>-ów), można szacować
regresję względem ryzyka dla <span class="math inline">\(Y\)</span> (czyli <strong>prawdopodobieństwa</strong>, że <span class="math inline">\(Y\)</span> przyjmie wartość 1).
Tutaj znowu pojawia się jednak trudność, bo ryzyko może przyjąć tylko wartości
z przedziału <span class="math inline">\([0,1]\)</span>.
Nie wchodząc w matematyczne zawiłości,
model zapisuje się jako (ln oznacza logarytm naturalny):</p>
<p><span class="math display">\[\ln(\frac{p}{1-p}) = b_0 + b_1 \cdot x_1  + \ldots + b_k \cdot x_k\]</span></p>
<p>Zauważmy, że <span class="math inline">\(o = \frac{p}{1-p}\)</span> to nic innego jak szansa (<em>odds</em>, por. punkt <a href="causality.html#oddsSec">4.1.1</a>).
Parametr <span class="math inline">\(b_i\)</span> jest miarą wpływu zmiennej <span class="math inline">\(X_i\)</span> na zmienną <span class="math inline">\(Y\)</span>.
Jeżeli <span class="math inline">\(X_i\)</span> wzrośnie o jednostkę, to logarytm ilorazu szans
wzrośnie o <span class="math inline">\(b_i\)</span> (przy założeniu, że pozostałe zmienne <span class="math inline">\(X\)</span> mają
pewne ustalone wartości, a zmienia się tylko <span class="math inline">\(X_i\)</span>).
Jeżeli <span class="math inline">\(X_i\)</span> jest zmienną <strong>dwuwartościową</strong>
to interpretacja jest jeszcze prostsza: jest to logarytm ilorazu szans
dla wartości <span class="math inline">\(X_i=1\)</span> względem <span class="math inline">\(X_i=0\)</span>.</p>
<p>Zwykle zamiast <strong>logarytmu ilorazu szans</strong> wolimy interpretować zmianę w kategoriach
<strong>ilorazu szans</strong>. Aby otrzymać ów iloraz, należy wykonać następujące
przekształcenie (<span class="math inline">\(\exp\)</span> oznacza podstawę logarytmu naturalnego):</p>
<p><span class="math display">\[o = \exp^{\ln(o)}\]</span></p>
<p>Zwykle iloraz szans wyraża się
w procentach, czyli mnoży przez 100. Jeżeli ta liczba jest większa od 100, oznacza
to wzrost szansy, a jeżeli mniejsza od 100, spadek szansy.</p>
<p><strong>Ocena dopasowania</strong></p>
<p>Nie ma w przypadku regresji logistycznej możliwości obliczenia sumy
kwadratów reszt czy współczynnika zbieżności.
Model ocenia się,
używając jako kryterium <strong>dewiancję</strong> (<em>deviance</em>), której
wielkość zależy od proporcji pomiędzy liczbą sukcesów obliczonych
na podstawie modelu a liczbą sukcesów zaobserwowanych.
Dewiancja będzie tym większa, im różnica między tymi
teoretycznymi liczebnościami a liczebnościami empirycznymi będzie większa.</p>
<p>Porównuje się wielkość dewiancji szacowanego modelu
z modelem zerowym (<em>null model</em>), tj. modelem, w którym po prawej stronie
równania występuje tylko stała. Wyjaśnijmy to na przykładzie
prostego modelu pomiędzy wystąpieniem osteoporozy a płcią, który ma postać:</p>
<p><span class="math display">\[\ln(o) = b_0 + b_1 \cdot \textrm{płeć}\]</span></p>
<p>Model zerowy ma postać:</p>
<p><span class="math display">\[\ln(o) = b_0\]</span></p>
<p>W modelu zerowym prawdopodobieństwo osteoporozy jest identyczne dla
kobiet i mężczyzn, zatem w oczywisty sposób dewiancja tego modelu
będzie większa. Pytanie, czy różnica jest istotna statystycznie.
Jeżeli jest, to przyjmuje się, że szacowany model jest lepszy od modelu
trywialnego (warunek minimum przydatności).</p>
<p>Zamiast współczynnika zbieżności <span class="math inline">\(R^2\)</span> stosuje się
współczynniki pn. pseudo-<span class="math inline">\(R^2\)</span>, takie jak pseudo-<span class="math inline">\(R^2\)</span> McFaddena lub pseudo-<span class="math inline">\(R^2\)</span> Nagelkerke.
Ich interpretacja
jest podobna do „normalnego“ <span class="math inline">\(R^2\)</span>: im bliżej zera, tym gorzej, im
bliżej jedności, tym lepiej.</p>
<p>Minimalne kryteria oceny przydatności modelu regresji logistycznej:
mała dewiancja, duże wartości współczynników pseudo-<span class="math inline">\(R^2\)</span>,
dewiancja istotnie mniejsza od modelu zerowego
oraz
istotnie różne od zera parametry przy zmiennych niezależnych.</p>
<p><strong>Ocena skuteczności klasyfikacji</strong></p>
<p>Model regresji logistycznej nie oblicza wartości zmiennej prognozowanej,
bo ta nie jest liczbą, tylko <strong>klasyfikuje</strong>, tj. ustala (albo prognozuje) wartość
zmiennej nominalnej w kategoriach „sukces”/„porażka”.
Ważnym kryterium oceny jakości modelu jest ocena jakości
klasyfikacji, to jest ocena, na ile model poprawnie
przypisuje przypadkom kategorie zmiennej prognozowanej. Im mniejsza
rozbieżność pomiędzy wartościami rzeczywistymi a prognozowanymi, tym oczywiście lepiej.</p>
<p>Klasyfikacja w modelu regresji logistycznej wygląda następująco:
jeżeli prawdopodobieństwo obliczone z modelu
jest wyższe od przyjętej <strong>wartości granicznej</strong> (<span class="math inline">\(p_g\)</span>) lub jej równe, to zakładamy „sukces”,
jeżeli tak nie jest, to zakładamy „porażkę”.
Wartość <span class="math inline">\(p_g\)</span> jest ustalana albo
arbitralnie, albo na podstawie jakieś dodatkowej (pozastatystycznej) informacji.
Domyślnie przyjmuje się zwykle <span class="math inline">\(p_g = 0,5\)</span>, co oznacza, że
wartości <span class="math inline">\(p \geq 0,5\)</span> zostaną zamienione na „sukces”,
a wartości <span class="math inline">\(p &lt; 0,5\)</span> na „porażkę”.</p>
<p><strong>Macierz błędów</strong></p>
<p>Tabela dwudzielna przedstawiająca rozkład wartości prognozowanych i wartości empirycznych
nazywa się macierzą błędów (<em>confussion matrix</em>), por. rysunek <a href="causality.html#fig:ConfMx">4.5</a>.</p>
<div class="figure"><span style="display:block;" id="fig:ConfMx"></span>
<img src="ConfussionMatrix.png" alt="Macierz błędów" width="75%" />
<p class="caption">
Rysunek 4.5: Macierz błędów
</p>
</div>
<p>Poszczególne rubryki macierzy błędów zawierają liczbę:
sukcesów zaklasyfikowanych jako „sukces” (<em>true positive</em>, TP),
sukcesów zaklasyfikowanych jako „porażka” (<em>false positive</em>, FP),
porażek zaklasyfikowanych jako „porażka” (<em>true negative</em>, TN)
oraz porażek zaklasyfikowanych jako „sukces” (<em>false negative</em>, FN).</p>
<p>Jakość klasyfikacji ocenia się także za pomocą dwóch wskaźników:
<strong>czułości</strong> (<em>sensitivity</em>) oraz <strong>swoistości</strong> (<em>specifity</em>).</p>
<p>Czułość to odsetek sukcesów zaklasyfikowanych jako „sukces”
(<span class="math inline">\(\mathrm{TP}/(\mathrm{TP}+\mathrm{FN})\)</span>).
Swoistość to odsetek porażek zaklasyfikowanych
jako „porażka” (<span class="math inline">\(\mathrm{TN}/(\mathrm{TN} + \mathrm{TP})\)</span>).</p>
<p><strong>Ocena dopasowania: krzywa ROC</strong></p>
<p>Czułość oraz swoistość zależą od prawdopodobieństwa granicznego.
Im wyższa
jest wartość prawdopodobieństwa granicznego, tym mniej będzie „sukcesów“.</p>
<p>Krzywa ROC przedstawia w układzie współrzędnych XY wartości
czułości oraz swoistości dla wybranych wartości granicznych.</p>
<p>Współczynnik AUC (<em>area under curve</em>) to wielkość pola pod
krzywą wyrażona w procentach pola kwadratu o boku 100%.
AUC zawiera się w przedziale 50–100. Im większa wartość współczynnika, tym lepiej.
Model, który klasyfikuje czysto losowo,
ma wartość AUC równą 50% (por. rysunek <a href="causality.html#fig:ROCcurve">4.6</a>).</p>
<div class="figure"><span style="display:block;" id="fig:ROCcurve"></span>
<img src="ROCcurve.png" alt="Krzywa ROC" width="75%" />
<p class="caption">
Rysunek 4.6: Krzywa ROC
</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-40" class="example"><strong>4.20  </strong></span><strong>Osteoporoza i witamina D</strong></p>
<p>Al Zarooni A.A.R i inni badali wpływ różnych czynników,
takich jak deficyt witaminy D, wiek oraz płeć,
na ryzyko
wystąpienia osteoporozy (Risk factors for vitamin D deficiency
in Abu Dhabi Emirati population; <a href="https://doi.org/10.1371/journal.pone.0264064" class="uri">https://doi.org/10.1371/journal.pone.0264064</a>),
w grupie 392 osób, w tym 242
kobiet (21 przypadków osteoporozy)
oraz 150 mężczyzn (5 przypadków osteoporozy).</p>
<p>Zacznijmy od modelu zerowego, tj. takiego, w którym szansa
wystąpienia osteoporozy jest takie sama bez względu na wielkości innych zmiennych.
Odpowiada to następującemu równaniu:</p>
<p><span class="math display">\[\ln(o) = -2,644540\]</span></p>
<p>Można obliczyć, że (teoretyczne) prawdopodobieństwo wystąpienia osteoporozy
wyniosło 0,0663265. Zatem teoretyczna liczba przypadków osteoporozy
wyniesie<br />
0,0663265 <span class="math inline">\(\cdot\)</span> 242 =
16,05 (kobiety) oraz
0,0663265 <span class="math inline">\(\cdot\)</span> 150 =
9,95 (mężczyźni). Dla przypomnienia empiryczne
wartości były równe odpowiednio 21 oraz 5.</p>
<p>Krzywa ROC dla modelu zerowego wygląda następująco:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-70-1.png" width="75%" /></p>
<p>Model zerowy, jak sama nazwa wskazuje, może tylko służyć do porównania
z bardziej skomplikowanymi modelami.</p>
<p>Takim bardziej skomplikowanym modelem będzie przykładowo
zależność pomiędzy wystąpieniem osteoporozy a płcią, którą
można opisać następującym równaniem regresji:</p>
<p><span class="math display">\[\ln(o) = b_0 + b_1 \cdot \textrm{kobieta}\]</span></p>
<p>Zmienna <code>kobieta</code> przyjmuje wartość 1, jeżeli osoba była kobietą, oraz 0, jeżeli była mężczyzną.</p>
<p>W tabeli zestawiono wartości parametrów oszacowanego modelu (<code>Ocena</code>),
oceny błędu standardowego parametrów (<code>SE</code>),
ilorazu szans (<code>OR</code>), przedziału ufności parametrów
dla ilorazu szans (CI95) oraz prawdopodobieństwo służące do oceny istotności parametru (<code>p</code>).</p>
<table>
<thead>
<tr class="header">
<th align="left">Parametr</th>
<th align="right">Ocena</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">OR</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-3,367</td>
<td align="right">0,455</td>
<td align="right">-7,403</td>
<td align="right">0,000</td>
<td align="right">0,03</td>
<td align="left">0,01 0,08</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">1,014</td>
<td align="right">0,509</td>
<td align="right">1,992</td>
<td align="right">0,046</td>
<td align="right">2,76</td>
<td align="left">1,09 8,40</td>
</tr>
</tbody>
</table>
<p>Szansa na wystąpienie osteoporozy jest 2,76 raza większa u kobiety niż u mężczyzny.</p>
<p>Można obliczyć, że (teoretyczne) prawdopodobieństwo wystąpienia osteoporozy
wyniosło 0,0868 (kobieta) oraz 0,0333 (mężczyzna).
Zatem teoretyczna liczba przypadków osteoporozy
wyniesie 21 (kobiety) oraz
5 (mężczyźni). Dla przypomnienia empiryczne
wartości były równe odpowiednio 21
oraz 5.</p>
<p>Dewiancja modelu (186,63) jest istotnie mniejsza
od modelu zerowego (191,32), ponieważ wartość <span class="math inline">\(p\)</span> wynosi 0,0304.
Wartość współczynnika pseudo-<span class="math inline">\(R^2\)</span> McFaddena wyniosła 0,0245,
a pseudo-<span class="math inline">\(R^2\)</span> Nagelkerke wyniosła 0,0308.</p>
<p>Zależność pomiędzy wystąpieniem osteoporozy a płcią (<code>genderF</code>), wiekiem (<code>age</code>) oraz poziomem witaminy D
(<code>d</code>) można opisać następującym równaniem regresji:</p>
<p><span class="math display">\[\ln(o) = b_0 + b_1 \cdot \textrm{genderF} + b_2 \cdot \textrm{age} + b_3 \cdot \textrm{d}\]</span></p>
<p>W tabeli zestawiono wartości parametrów oszacowanego modelu,
oceny błędu standardowego parametrów,
ilorazu szans, przedziału ufności parametrów
dla ilorazu szans oraz prawdopodobieństwo służące do oceny istotności parametru.</p>
<table>
<thead>
<tr class="header">
<th align="left">Parametr</th>
<th align="right">Ocena</th>
<th align="right">SE</th>
<th align="right">z</th>
<th align="right">p</th>
<th align="right">OR</th>
<th align="left">CI95</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-12,183</td>
<td align="right">1,766</td>
<td align="right">-6,898</td>
<td align="right">0,000</td>
<td align="right">0,00</td>
<td align="left">0,00 0,00</td>
</tr>
<tr class="even">
<td align="left">d</td>
<td align="right">0,005</td>
<td align="right">0,009</td>
<td align="right">0,536</td>
<td align="right">0,592</td>
<td align="right">1,00</td>
<td align="left">0,99 1,02</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0,156</td>
<td align="right">0,026</td>
<td align="right">5,930</td>
<td align="right">0,000</td>
<td align="right">1,17</td>
<td align="left">1,12 1,24</td>
</tr>
<tr class="even">
<td align="left">genderF</td>
<td align="right">2,463</td>
<td align="right">0,662</td>
<td align="right">3,722</td>
<td align="right">0,000</td>
<td align="right">11,74</td>
<td align="left">3,54 48,76</td>
</tr>
</tbody>
</table>
<p>Dewiancja modelu (121,73) jest istotnie mniejsza
od modelu zerowego (191,32), ponieważ wartość <span class="math inline">\(p\)</span> wynosi 0.
Wartość współczynnika pseudo-<span class="math inline">\(R^2\)</span> McFaddena wyniosła 0,3637
a pseudo-<span class="math inline">\(R^2\)</span> Nagelkerke wyniosła 0,4212.</p>
<p>Parametr <code>d</code> okazał się nieistotny statystycznie. Każdy rok (<code>age</code>) zwiększa szanse na osteoporozę
o 17%, Kobiety mają ponad 11-krotnie większe szanse na osteoporozę niż mężczyźni.</p>
<p>Macierz błędów dla <span class="math inline">\(p_g = 0,5\)</span>:</p>
<pre><code>##         Osteoporoza
## Prognoza nie tak
##      nie 362  22
##      tak   4   4</code></pre>
<p>Stąd: czułość 4 / (22 + 4) = 0,1538462;
swoistość 362 / (362 + 4) = 0,989071.
Model regresji logistycznej poprawnie klasyfikuje
15,38% przypadków osteoporozy
oraz 98,91% przypadków braku osteoporozy.</p>
<p>Krzywa ROC</p>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="75%" /></p>
</div>
</div>
<div id="przypadek-specjalny-co-najmniej-dwie-zmienne-porządkowe" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Przypadek specjalny: co najmniej dwie zmienne porządkowe<a href="causality.html#przypadek-specjalny-co-najmniej-dwie-zmienne-porządkowe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="pomiar-siły-zależności-współczynnik-korelacji-rang" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Pomiar siły zależności: współczynnik korelacji rang<a href="causality.html#pomiar-siły-zależności-współczynnik-korelacji-rang" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Współczynnik korelacji rang Spearmana (<em>Spearman’s Rank-Order Correlation</em>)
może być stosowany
w przypadku, gdy cechy są mierzone w skali porządkowej (lub lepszej, czyli liczbowej).</p>
<p>Obliczenie współczynnika Spearmana dla <span class="math inline">\(N\)</span> obserwacji na zmiennych <span class="math inline">\(XY\)</span>
polega na zamianie wartości
zmiennych <span class="math inline">\(X\)</span> oraz <span class="math inline">\(Y\)</span> na <strong>rangi</strong> (numery porządkowe od <span class="math inline">\(1\)</span> do <span class="math inline">\(N\)</span>).
Następnie stosowana jest formuła współczynnika korelacji
liniowej Pearsona (<span class="math inline">\(\tau_x\)</span> oraz <span class="math inline">\(\tau_y\)</span> oznaczają <strong>rangi</strong>):</p>
<p><span class="math display">\[\rho_{xy} = \frac{\textrm{cov}(\tau_x, \tau_y)}{s_{\tau_x}  s_{\tau_y}}\]</span></p>
<p>Współczynnik <span class="math inline">\(\rho_{xy}\)</span> to – podobnie jak <strong>oryginalny</strong> współczynnik
korelacji liniowej Pearsona – miara niemianowana, o wartościach
ze zbioru [-1;1].</p>
<div class="example">
<p><span id="exm:unlabeled-div-41" class="example"><strong>4.21  </strong></span><strong>Spożycie mięsa</strong></p>
<p>Współczynnik Pearsona i Spearmana dla zależności między spożyciem mięsa w 1980
a spożyciem mięsa w 2013 roku (zmienna objaśniana):</p>
<ul>
<li><p>współczynnik Pearsona: 0,68;</p></li>
<li><p>współczynnik Spearmana: 0,68.</p></li>
</ul>
<p>Nie ma sensu liczenie współczynnika korelacji rang w przypadku, kiedy obie
cechy są liczbami, bo wtedy należy użyć normalnego współczynnika Pearsona.
Ale nie jest to też błędem, więc w powyższym przykładzie go liczymy.</p>
<p>Współczynnik korelacji liniowej Spearmana
wynosi 0,68 (umiarkowana korelacja).</p>
<p>Czy ta wartość jest istotnie różna od zera? Jest na to stosowny
test statystyczny, który sprowadza się do określenia, jakie jest
prawdopodobieństwo otrzymania <span class="math inline">\(r_s\)</span> = 0,68 przy założeniu, że
prawdziwa wartość <span class="math inline">\(r_s\)</span> wynosi 0. Otóż w naszym przykładzie
to prawdopodobieństwo wynosi 2.302116e-26
(czyli jest ekstremalnie małe – współczynnik jest istotnie różny od zera).</p>
</div>
</div>
</div>
<div id="podsumowanie" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Podsumowanie<a href="causality.html#podsumowanie" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Przedstawiono 7 następujących metod ustalania zależności między zmiennymi:</p>
<ol style="list-style-type: decimal">
<li><p>Wykres rozrzutu.</p></li>
<li><p>Tablica wielodzielna i test chi-kwadrat.</p></li>
<li><p>Współczynnik korelacji liniowej Pearsona.</p></li>
<li><p>Współczynnik korelacji Spearmana.</p></li>
<li><p>Regresja liniowa.</p></li>
<li><p>Regresja logistyczna.</p></li>
<li><p>Testy <span class="math inline">\(t\)</span> Welcha, U Manna-Whitneya, ANOVA albo test Kruskala-Wallisa.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="surveyexamples.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/04causality.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
